# wbm_soilM_crop_uc_lafferty-etal-2024-tbd

**Combined climate and hydrologic uncertainties shape projections of future soil moisture in the central and eastern United States**

*David C. Lafferty<sup>1\*a</sup>, Danielle S. Grogan<sup>2</sup>, Shan Zuidema<sup>2</sup>, Iman Haqiqi<sup>3</sup>, Atieh Alipour<sup>4b</sup>, Ryan L. Sriver<sup>1</sup>, Klaus Keller <sup>4</sup>*

<sup>1 </sup>Department of Climate, Meteorology, \& Atmospheric Sciences, University of Illinois Urbana-Champaign\
<sup>2 </sup>Institute for the Study of Earth, Oceans, and Space, University of New Hampshire\
<sup>3 </sup>Department of Agricultural Economics, Purdue University\
<sup>3 </sup>Thayer School of Engineering, Dartmouth College

\* corresponding author:  `dcl257@cornell.edu`\
<sup>a </sup> Current address: Department of Biological & Environmental Engineering, Cornell University\
<sup>b </sup> Current address: National Oceanic & Atmospheric Administration

## Abstract
Climate change is altering the frequency and intensity of physical hazards worldwide, magnifying the risks to many systems that provide critical services to humanity such as agriculture and water resources. In a hydrologic context, quantifying these risks is challenging due to large uncertainties in modeling the future climate change and the associated hydrologic response. Here, we examine the combined role of climate and hydrologic uncertainties in shaping projections of future soil moisture. We focus on the central and eastern United States given its significance to global maize and soybean production. We encode a conceptual model of soil moisture in a differentiable programming framework to facilitate faster runtimes and a more efficient calibration. We characterize and analyze uncertainty in model parameters by calibrating against different targets, including satellite- and reanalysis-derived products such as SMAP and NLDAS-2, as well as using several error metric functions. We then convolve the resulting parameter ensemble with a set of downscaled and bias-corrected climate projections to produce a large ensemble ($\sim$2200 members) of daily soil moisture simulations at $\sim$12.5 km resolution over the domain. We conduct sensitivity analyses on a variety of soil moisture metrics, some targeting long-term trends and others short-lived extremes, to measure the relative influence of climate and hydrologic-parameter uncertainties across space and time. Across most of the region, we find weak but statistically significant drying trends in mean and extreme soil moisture metrics, with both climate and parametric factors contributing non-negligible uncertainty. Our sensitivity analyses also reveal a distinct spatial pattern, where hydrologic uncertainty is more important (relative to climate) for projecting dry extremes in dry areas, and wet extremes in wet areas. Our results highlight the importance of considering combined hydrologic and climate uncertainties when constructing projections of decision-relevant hydroclimatic outcomes.

## Journal reference
_your journal reference_

## Code reference
References for each minted software release for all code involved.  

These are generated by Zenodo automatically when conducting a release when Zenodo has been linked to your GitHub repository. The Zenodo references are built by setting the author order in order of contribution to the code using the author's GitHub username.  This citation can, and likely should, be edited without altering the DOI.

If you have modified a codebase that is outside of a formal release, and the modifications are not planned on being merged back into a version, fork the parent repository and add a `.<shortname>` to the version number of the parent and construct your own name.  For example, `v1.2.5.hydro`.

_your software reference here_

## Data reference

### Input data
Reference for each minted data source for your input data.  For example:

Human, I.M. (2021). My input dataset name [Data set]. DataHub. https://doi.org/some-doi-number

_your input data references here_

### Output data
Reference for each minted data source for your output data.  For example:

Human, I.M. (2021). My output dataset name [Data set]. DataHub. https://doi.org/some-doi-number

_your output data references here_


## Contributing modeling software
| Model | Version | Repository Link | DOI |
|-------|---------|-----------------|-----|
| model 1 | version | link to code repository | link to DOI dataset |
| model 2 | version | link to code repository | link to DOI dataset |
| component 1 | version | link to code repository | link to DOI dataset |

## Reproduce my experiment
Fill in detailed info here or link to other documentation to thoroughly walkthrough how to use the contents of this repository to reproduce your experiment. Below is an example.


1. Install the software components required to conduct the experiment from [contributing modeling software](#contributing-modeling-software)
2. Download and install the supporting [input data](#input-data) required to conduct the experiment
3. Run the following scripts in the `workflow` directory to re-create this experiment:

| Script Name | Description | How to Run |
| --- | --- | --- |
| `step_one.py` | Script to run the first part of my experiment | `python3 step_one.py -f /path/to/inputdata/file_one.csv` |
| `step_two.py` | Script to run the second part of my experiment | `python3 step_two.py -o /path/to/my/outputdir` |

4. Download and unzip the [output data](#output-data) from my experiment 
5. Run the following scripts in the `workflow` directory to compare my outputs to those from the publication

| Script Name | Description | How to Run |
| --- | --- | --- |
| `compare.py` | Script to compare my outputs to the original | `python3 compare.py --orig /path/to/original/data.csv --new /path/to/new/data.csv` |

## Reproduce my figures
Use the scripts found in the `figures` directory to reproduce the figures used in this publication.

| Figure Number(s) | Script Name | Description | How to Run |
| --- | --- | --- | --- |
| 1, 2 | `generate_plot.py` | Description of figure, ie. "Plots the difference between our two scenarios" | `python3 generate_plot.py -input /path/to/inputs -output /path/to/outuptdir` |
| 3 | `generate_figure.py` | Description of figure, ie. "Shows how the mean and peak differences are calculated" | `python3 generate_figure.py -input /path/to/inputs -output /path/to/outuptdir` |
