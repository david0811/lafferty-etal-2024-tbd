{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9984a47f-6330-4ba1-940e-cd2b44c7d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import pandas as pd\n",
    "import dask\n",
    "import zarr\n",
    "\n",
    "from utils.param_names import param_names\n",
    "from utils.initial_params import constants\n",
    "from utils.subsets import subsets\n",
    "from utils.global_paths import project_data_path, project_code_path, loca_path\n",
    "from src.read_inputs import read_projection_inputs\n",
    "from src.prediction import make_prediction_vmap\n",
    "from src.data_processing import _subset_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c00432-5456-4494-961e-f3c2f31e1907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-dafaa659-01bf-11ef-a208-00001029fe80</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.SLURMCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">SLURMCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">94eec346</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-7911ab3c-0bd0-4d61-8722-9e7e4844f0f4</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.6.0.159:46733\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.6.0.159:46733' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "### Dask ###\n",
    "############\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    account=\"pches\",\n",
    "    # account=\"open\",\n",
    "    cores=1,\n",
    "    memory=\"60GiB\",\n",
    "    walltime=\"02:00:00\"\n",
    ")\n",
    "cluster.scale(jobs=30)  # ask for jobs\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9c107d-20d3-480b-9a76-b9d1a2b3ea29",
   "metadata": {},
   "source": [
    "# LOCA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d45070b-e843-48f0-b98d-470f2b4d925d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# models: 27\n",
      "# model/expts: 99\n",
      "# model/expts/ens: 329\n",
      "# model/expts/ens (not including historical): 221\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "### Models ###\n",
    "##############\n",
    "\n",
    "models = os.listdir(f\"{loca_path}/\")\n",
    "models.remove('training_data')\n",
    "models.remove('scripts')\n",
    "\n",
    "loca_all = {}\n",
    "\n",
    "# Loop through models\n",
    "for model in models:\n",
    "    loca_all[model] = {}\n",
    "    # Loop through members\n",
    "    members = os.listdir(f\"{loca_path}/{model}/0p0625deg/\")\n",
    "    for member in members:\n",
    "        # Append SSPs\n",
    "        ssps = os.listdir(f\"{loca_path}/{model}/0p0625deg/{member}/\")\n",
    "        loca_all[model][member] = ssps\n",
    "\n",
    "# Matches website (https://loca.ucsd.edu/loca-version-2-for-north-america-ca-jan-2023/) as of Jan 2023\n",
    "print(f\"# models: {len(models)}\")\n",
    "print(f\"# model/expts: {np.sum([len(np.unique([item for row in [loca_all[model][member] for member in loca_all[model].keys()] for item in row])) for model in models])}\")\n",
    "print(f\"# model/expts/ens: {np.sum([len(loca_all[model][ssp]) for model in models for ssp in loca_all[model]])}\")\n",
    "print(f\"# model/expts/ens (not including historical): {np.sum([len([ssp for ssp in loca_all[model][member] if ssp != 'historical']) for model in models for member in loca_all[model]])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed34696-f271-4aa4-99bf-6bd18808d604",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Regridding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe5d170d-b8d6-4645-8f1b-5148621b4edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Regrid function\n",
    "###################\n",
    "def regrid_subset(model, member, ssp, subset_name, list_of_states):\n",
    "    # Read inputs\n",
    "    tasmin_in = xr.open_mfdataset(f\"{loca_path}/{model}/0p0625deg/{member}/{ssp}/tasmin/*.nc\", chunks=\"auto\")\n",
    "    tasmin_in[\"tasmin\"] = tasmin_in[\"tasmin\"] - 273.15\n",
    "    tasmin_in[\"tasmin\"].attrs[\"units\"] = \"degC\"\n",
    "    \n",
    "    tasmax_in = xr.open_mfdataset(f\"{loca_path}/{model}/0p0625deg/{member}/{ssp}/tasmax/*.nc\", chunks=\"auto\")\n",
    "    tasmax_in[\"tasmax\"] = tasmax_in[\"tasmax\"] - 273.15\n",
    "    tasmax_in[\"tasmax\"].attrs[\"units\"] = \"degC\"\n",
    "\n",
    "    tas_in = (tasmin_in[\"tasmin\"] + tasmax_in[\"tasmax\"]) / 2.0\n",
    "    tas_in.attrs[\"units\"] = \"degC\"\n",
    "    \n",
    "    pr_in = xr.open_mfdataset(f\"{loca_path}/{model}/0p0625deg/{member}/{ssp}/pr/*.nc\", chunks=\"auto\")\n",
    "    pr_in[\"pr\"] = pr_in['pr'] * 86400\n",
    "    pr_in[\"pr\"].attrs[\"units\"] = \"mm/day\"\n",
    "\n",
    "    # Merge\n",
    "    ds_in = xr.merge([xr.Dataset({\"tas\": tas_in}), pr_in])\n",
    "\n",
    "    # Construct out grid\n",
    "    nldas_lats = np.load(f\"{project_code_path}/code/utils/grids/{subset_name}_lat.npy\")\n",
    "    nldas_lons = np.load(f\"{project_code_path}/code/utils/grids/{subset_name}_lon.npy\")\n",
    "\n",
    "    dr_out = xr.Dataset({\n",
    "        \"lat\": ([\"lat\"], nldas_lats,\n",
    "                {\"standard_name\": \"latitude\", \"units\": \"degrees_north\"},),\n",
    "        \"lon\": ([\"lon\"], nldas_lons,\n",
    "                {\"standard_name\": \"longitude\", \"units\": \"degrees_east\"},),\n",
    "    })\n",
    "\n",
    "    # Regrid conservatively\n",
    "    regridder = xe.Regridder(ds_in, dr_out, \"conservative\")\n",
    "    ds_out = regridder(ds_in, skipna=True, na_thres=0.99) # This threshold is somewhat subjective\n",
    "\n",
    "    # Subset to states\n",
    "    ds_out = _subset_states(ds_out, list_of_states)\n",
    "    \n",
    "    # Store \n",
    "    ds_out = ds_out.chunk({'time': 200 , 'lat':-1, 'lon':-1})\n",
    "    compressor = zarr.Blosc(cname=\"zstd\", clevel=3)\n",
    "    encoding = {vname: {\"compressor\": compressor} for vname in ds_out.data_vars}\n",
    "    ds_out.to_zarr(f\"{project_data_path}/projections/{subset_name}/forcing/LOCA2/{model}_{member}_{ssp}.zarr\",\n",
    "                   encoding=encoding, mode='w-', consolidated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f21e7c3-539c-4d9f-a072-c1b1fd54deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## File path function\n",
    "def make_loca_file_path(loca_path, model, member, ssp, var):\n",
    "    \"\"\"\n",
    "    Returns list of file paths for a given downscaled LOCA output.\n",
    "    \"\"\"\n",
    "    out_path = f\"{loca_path}/{model}/0p0625deg/{member}/{ssp}/{var}\"\n",
    "\n",
    "    if os.path.isdir(out_path):\n",
    "        files = os.listdir(out_path)\n",
    "        files = [file for file in files if file[-7:] != 'ORIG.nc'] # Skip ORIGs (had to fix tasmin naming errors)\n",
    "        return files\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c0154d-f68d-43f2-bc89-135c19234770",
   "metadata": {},
   "source": [
    "### eCONUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07f8c3e8-5429-41e0-8cd2-1a102bd1ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_name = \"eCONUS\"\n",
    "list_of_states = subsets[subset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bdffc89-2743-4288-b25a-cf55ccfe591d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/xarray/core/indexing.py:1446: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 14.07 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INM-CM5-0_r3i1p1f1_ssp370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/xarray/core/indexing.py:1446: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 14.12 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INM-CM5-0_r4i1p1f1_ssp370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/xarray/core/indexing.py:1446: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 14.13 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/xarray/core/indexing.py:1446: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 14.12 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPSL-CM6A-LR_r4i1p1f1_ssp245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/xarray/core/indexing.py:1446: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 14.07 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPSL-CM6A-LR_r5i1p1f1_ssp245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/xarray/core/indexing.py:1446: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 14.07 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPSL-CM6A-LR_r7i1p1f1_ssp370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: MPI-ESM1-2-LR ssp585 r10i1p1f1\n",
      "MPI-ESM1-2-LR_r10i1p1f1_ssp585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/xarray/core/indexing.py:1446: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.77 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-LR_r4i1p1f1_ssp585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: MPI-ESM1-2-LR ssp585 r5i1p1f1\n",
      "MPI-ESM1-2-LR_r5i1p1f1_ssp585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: MPI-ESM1-2-LR ssp585 r6i1p1f1\n",
      "MPI-ESM1-2-LR_r6i1p1f1_ssp585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: MPI-ESM1-2-LR ssp585 r7i1p1f1\n",
      "MPI-ESM1-2-LR_r7i1p1f1_ssp585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: MPI-ESM1-2-LR ssp585 r8i1p1f1\n",
      "MPI-ESM1-2-LR_r8i1p1f1_ssp585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "/storage/home/dcl5300/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/distributed/client.py:3162: UserWarning: Sending large graph of size 13.39 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42min 7s, sys: 1min 40s, total: 43min 47s\n",
      "Wall time: 2h 36min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] yaksa: 10 leaked handle pool objects\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loop through models\n",
    "for model in models:\n",
    "    # Loop through members\n",
    "    for member in loca_all[model].keys():\n",
    "        # Loop through SSPs\n",
    "        for ssp in loca_all[model][member]:\n",
    "            if ssp == \"historical\":\n",
    "                continue\n",
    "            # Some vars are missing for some outputs: skip\n",
    "            file_paths = make_loca_file_path(loca_path, model, member, ssp, \"tasmin\")\n",
    "            if len(file_paths) == 0:\n",
    "                print(f\"Missing: {model} {ssp} {member}\")\n",
    "\n",
    "            # Check if done\n",
    "            if not os.path.exists(f\"{project_data_path}/projections/{subset_name}/forcing/LOCA2/{model}_{member}_{ssp}.zarr\"):\n",
    "                # Re-grid and subset\n",
    "                try:\n",
    "                    regrid_subset(model=model,\n",
    "                                  member=member,\n",
    "                                  ssp=ssp,\n",
    "                                  subset_name=subset_name,\n",
    "                                  list_of_states=list_of_states)\n",
    "                except:\n",
    "                    print(f\"{model}_{member}_{ssp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aec3e4-a702-4430-84d1-d826ace44f4f",
   "metadata": {},
   "source": [
    "## Run projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fe4311-a78e-483d-910f-bac3876166e3",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d0bfd8-e158-4f02-b957-dcb3796267a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_res(subset_name, obs_name, loss_metric, metrics_include, best_metric):\n",
    "    \"\"\"\n",
    "    Reads the training results\n",
    "    \"\"\"\n",
    "    # Loop through files\n",
    "    files = glob(f'{project_data_path}/WBM/calibration/{subset_name}/{obs_name}/training_res/*.txt')\n",
    "\n",
    "    df_out = []\n",
    "    for file in files:\n",
    "        # Read\n",
    "        df = pd.read_csv(file, sep = ' ').dropna(how='any')\n",
    "        df['epoch'] = df['epoch'].astype(np.float32)\n",
    "\n",
    "        # Add identifiers\n",
    "        _, param_id, val_id, _ = file.split('/')[-1].split('_')\n",
    "        df['param_id'] = param_id\n",
    "        df['val_id'] = val_id\n",
    "        \n",
    "        # Take best\n",
    "        df_best = df.query('epoch > 10').sort_values(by=loss_metric).iloc[:1]\n",
    "        if len(df_best) > 0:\n",
    "            df_out.append(df_best)\n",
    "\n",
    "    # Join\n",
    "    df_out = pd.concat(df_out).reset_index().drop(columns='index')\n",
    "\n",
    "    # Filter best result for each metric\n",
    "    if best_metric:\n",
    "        metric_min_inds = df_out.groupby('metric')[loss_metric].idxmin()\n",
    "        df_out = df_out.loc[metric_min_inds].reset_index().drop(columns='index')\n",
    "\n",
    "    # Subset metrics \n",
    "    if metrics_include != 'all':\n",
    "        df_out = df_out[df_out['metric'].isin(metrics_include)]\n",
    "\n",
    "    # Return\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e54089df-122f-4d5e-8692-77f25dca090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_projections(subset_name, obs_name, projection_id, loss_metric, loss_metrics_include, best_loss):\n",
    "    # Get soil parameters\n",
    "    df_res = get_training_res(subset_name, obs_name, loss_metric, loss_metrics_include, best_loss)\n",
    "\n",
    "    # Check if all done\n",
    "    if len(glob(f\"{project_data_path}/projections/{subset_name}/out/{projection_id}_{obs_name}_*\")) < len(df_res):\n",
    "        # Check forcing exists\n",
    "        if os.path.exists(f\"{project_data_path}/projections/{subset_name}/forcing/{projection_id}.zarr\"):\n",
    "            # Read all\n",
    "            x_forcing_nt, x_forcing_nyrs, x_maps, valid_inds = read_projection_inputs(subset_name, obs_name, projection_id, True)\n",
    "\n",
    "            # Need for out grid\n",
    "            lats = np.load(f\"{project_code_path}/code/utils/grids/{subset_name}_lat.npy\")\n",
    "            lons = np.load(f\"{project_code_path}/code/utils/grids/{subset_name}_lon.npy\")\n",
    "\n",
    "            # Loop through soil parameters\n",
    "            for iparam in range(len(df_res)):\n",
    "                # Check if already done\n",
    "                metric_id = df_res.iloc[iparam]['metric']\n",
    "                param_id = df_res.iloc[iparam]['param_id']\n",
    "                val_id = df_res.iloc[iparam]['val_id']\n",
    "                sim_id = f\"{obs_name}_{metric_id}_{param_id}_{val_id}\"\n",
    "\n",
    "                save_name = f\"{project_data_path}/projections/{subset_name}/out/{projection_id}_{sim_id}\"\n",
    "            \n",
    "                if not os.path.exists(f\"{save_name}.npz\"):\n",
    "                    # Run it\n",
    "                    theta = jnp.array([df_res.iloc[iparam][param] for param in param_names])\n",
    "                    out = make_prediction_vmap(theta, constants, x_forcing_nt, x_forcing_nyrs, x_maps)\n",
    "                    np.savez(save_name, out=out, valid_inds=valid_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c24f448-8e93-4dd1-b121-ea240af78723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate soil moisture metrics from daily simulations\n",
    "def calculate_soilMoist_metrics(subset_name, ensemble_name, file_name, metric, threshold):\n",
    "    \"\"\"\n",
    "    Metric can be [mean, 5dmin, 5dmax] calculated as a rolling 10-year anomaly or as a change\n",
    "    from the \"historical\" (i.e. calibration period) simulation. Metric takes from of (e.g.)\n",
    "    \"5dmin-change\". \n",
    "    \"\"\"\n",
    "    # Read simulation\n",
    "    sim_id = file_name.replace(\".npz\", \"\")\n",
    "    npz = np.load(f\"{project_data_path}/projections/{subset_name}/out/{ensemble_name}/{sim_id}.npz\")\n",
    "\n",
    "    ##### Check if done\n",
    "    if len(metric.split('-')) > 1:\n",
    "        metric_to_calc = metric.split('-')[0]\n",
    "        anom_type = metric.split('-')[1]\n",
    "    else:\n",
    "        metric_to_calc = metric\n",
    "        anom_type = \"\"\n",
    "\n",
    "    if metric_to_calc.split('_')[0] == \"days\":\n",
    "        metric_name = f\"{metric_to_calc}_{str(abs(int(threshold)))}\"\n",
    "    else:\n",
    "        metric_name = metric_to_calc\n",
    "\n",
    "    metric_name_final = metric_name + (bool(anom_type) * \"-\") + anom_type\n",
    "    if os.path.exists(f\"{project_data_path}/projections/{subset_name}/metrics/{metric_name_final}/{sim_id}.nc\"):\n",
    "        return None\n",
    "\n",
    "    # Construct xarray\n",
    "    lats = np.load(f\"{project_code_path}/code/utils/grids/{subset_name}_lat.npy\")\n",
    "    lons = np.load(f\"{project_code_path}/code/utils/grids/{subset_name}_lon.npy\")\n",
    "    nt = npz['out'].shape[1]\n",
    "    \n",
    "    out_full = np.full((len(npz['valid_inds']), nt), np.nan)\n",
    "    out_full[npz['valid_inds']] = npz['out']\n",
    "    \n",
    "    ds_sim = xr.Dataset(data_vars=dict(soilMoist=([\"time\", \"lat\", \"lon\"], \n",
    "                                                  np.transpose(out_full.reshape(len(lons), len(lats), nt), (2,1,0)))),\n",
    "                        coords=dict(lon=lons, lat=lats,\n",
    "                                    time=xr.cftime_range(start='2023-01-01', periods=nt, calendar='365_day')))\n",
    "\n",
    "    #### Calculate metric\n",
    "    def calculate_metric(ds, metric_to_calc, threshold=None):\n",
    "        # Mean\n",
    "        if metric_to_calc == \"mean\":\n",
    "            ds = ds.resample(time='1Y').mean()\n",
    "        # 5-day minima\n",
    "        elif metric_to_calc == \"5dmin\":\n",
    "            ds = ds.resample(time='5D').mean().resample(time=\"1Y\").min()\n",
    "        # 5-day maxima\n",
    "        elif metric_to_calc == \"5dmax\":\n",
    "            ds = ds.resample(time='5D').mean().resample(time=\"1Y\").max()\n",
    "        # Days above/below thresh\n",
    "        elif metric_to_calc.split('_')[0] == \"days\":\n",
    "            if metric == \"days_above\":\n",
    "                ds = (ds >= threshold).resample(time='1Y').sum()\n",
    "            elif metric == \"days_below\":\n",
    "                ds = (ds <= threshold).resample(time='1Y').sum()\n",
    "        return ds\n",
    "            \n",
    "    # Anomalies or not\n",
    "    if anom_type == \"anom\":\n",
    "        ds_out = ds_sim['soilMoist'] - ds_sim['soilMoist'].rolling(time=(365*10), center=True).mean()\n",
    "        ds_out = calculate_metric(ds_out, metric_to_calc)\n",
    "    elif anom_type == \"change\":\n",
    "        obs_name = sim_id.split('_')[3]\n",
    "        soil_id = '_'.join(sim_id.split('_')[4:])\n",
    "        ds_obs = xr.open_dataset(f\"{project_data_path}/WBM/calibration/{subset_name}/{obs_name}/hindcasts/best_only/{soil_id}.nc\")\n",
    "        ds_obs = calculate_metric(ds_obs, metric_to_calc).mean(dim=\"time\")\n",
    "        ds_sim = calculate_metric(ds_sim, metric_to_calc)\n",
    "        ds_out = ds_sim['soilMoist'] - ds_obs['soilMoist']\n",
    "    else:\n",
    "        ds_out = ds_sim['soilMoist']\n",
    "        ds_out = calculate_metric(ds_out, metric_to_calc)\n",
    "\n",
    "    ds_out = xr.Dataset({metric_name_final: ds_out})\n",
    "        \n",
    "    # Memory management\n",
    "    del ds_sim, npz\n",
    "    \n",
    "    # Get info\n",
    "    model, member, ssp, obs_name, loss_metric, param_id, val_id = sim_id.split('_')\n",
    "    projection_id = f\"{ensemble_name}/{model}_{member}_{ssp}\"\n",
    "    soil_id = f\"{obs_name}_{loss_metric}_{param_id}_{val_id}\"\n",
    "    \n",
    "    ds_out = ds_out.assign_coords(model=model)\n",
    "    ds_out = ds_out.assign_coords(member=member)\n",
    "    ds_out = ds_out.assign_coords(ssp=ssp)\n",
    "    ds_out = ds_out.assign_coords(obs_name=obs_name)\n",
    "    ds_out = ds_out.assign_coords(loss_metric=loss_metric)\n",
    "    ds_out = ds_out.assign_coords(param_id=param_id)\n",
    "    ds_out = ds_out.assign_coords(val_id=val_id)\n",
    "\n",
    "    ds_out = ds_out.assign_coords(projection_id=projection_id)\n",
    "    ds_out = ds_out.assign_coords(soil_id=soil_id)\n",
    "    \n",
    "    # Store\n",
    "    ds_out.to_netcdf(f\"{project_data_path}/projections/{subset_name}/metrics/{metric_name_final}/{sim_id}.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d09d26-7417-43aa-b721-d147771d54fa",
   "metadata": {},
   "source": [
    "### Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f724b1b-ebe2-417c-95bd-56bf2c9173ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "subset_name = 'eCONUS'\n",
    "loss_metric = 'pred_loss'\n",
    "\n",
    "loss_metrics_include = ['kge', 'nse', 'taylor',\n",
    "                   'rmse', 'ubrmse',\n",
    "                   'mae', 'ubmae', \n",
    "                   'mse', 'ubmse',\n",
    "                   'outer20rmse', 'outer20ubrmse',\n",
    "                   'outer50rmse', 'outer50ubrmse']\n",
    "\n",
    "best_loss = True\n",
    "\n",
    "n_member_min = 1\n",
    "ssps = ['ssp370', 'ssp245']\n",
    "ensemble_name = \"LOCA2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4142be2b-57c4-4294-90ca-585b5a2dc074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "CPU times: user 10.3 ms, sys: 1.6 ms, total: 11.9 ms\n",
      "Wall time: 13.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Loop through obs\n",
    "for obs_name in ['SMAP', 'VIC', 'NOAH', 'MOSAIC']:\n",
    "    # Loop through models\n",
    "    for model in models:\n",
    "        # Loop through members\n",
    "        if len(loca_all[model].keys()) >= n_member_min:\n",
    "            for member in list(loca_all[model].keys())[:1]:\n",
    "                # Loop through SSPs\n",
    "                for ssp in loca_all[model][member]:\n",
    "                    if ssp in ssps:\n",
    "                        # Run it\n",
    "                        projection_id = f\"LOCA2/{model}_{member}_{ssp}\"\n",
    "                        delayed.append(dask.delayed(run_projections)(subset_name,\n",
    "                                                                     obs_name,\n",
    "                                                                     projection_id,\n",
    "                                                                     loss_metric,\n",
    "                                                                     loss_metrics_include,\n",
    "                                                                     best_loss))\n",
    "    \n",
    "# Compute\n",
    "print(len(delayed))\n",
    "# _ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7154dd58-f0fd-4383-a87b-9a12ed8ba310",
   "metadata": {},
   "source": [
    "### Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e869c936-8633-4325-aaee-808aeaf3fdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "subset_name = 'eCONUS'\n",
    "ensemble_name = \"LOCA2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "872f88f5-e6bf-41f0-97a2-170635ffbb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2340\n",
      "CPU times: user 4.77 s, sys: 146 ms, total: 4.92 s\n",
      "Wall time: 5.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "soil_metric = \"mean-change\"\n",
    "threshold = None\n",
    "\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Get simulations\n",
    "file_names = os.listdir(f\"{project_data_path}/projections/{subset_name}/out/{ensemble_name}/\")\n",
    "\n",
    "# Run it\n",
    "for file_name in file_names:\n",
    "    # Only take first member\n",
    "    model, member = file_name.split('_')[:2]\n",
    "    if member == list(loca_all[model].keys())[0]:\n",
    "        delayed.append(dask.delayed(calculate_soilMoist_metrics)(subset_name=subset_name,\n",
    "                                                                 ensemble_name=ensemble_name,\n",
    "                                                                 file_name=file_name,\n",
    "                                                                 metric=soil_metric,\n",
    "                                                                 threshold=threshold))\n",
    "    \n",
    "# Compute\n",
    "print(len(delayed))\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15993948-c535-4736-bf32-237f03f2a762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2340\n",
      "CPU times: user 6.29 s, sys: 256 ms, total: 6.55 s\n",
      "Wall time: 15.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "soil_metric = \"5dmin-change\"\n",
    "threshold = None\n",
    "\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Get simulations\n",
    "file_names = os.listdir(f\"{project_data_path}/projections/{subset_name}/out/{ensemble_name}/\")\n",
    "\n",
    "# Run it\n",
    "for file_name in file_names:\n",
    "    # Only take first member\n",
    "    model, member = file_name.split('_')[:2]\n",
    "    if member == list(loca_all[model].keys())[0]:\n",
    "        delayed.append(dask.delayed(calculate_soilMoist_metrics)(subset_name=subset_name,\n",
    "                                                                 ensemble_name=ensemble_name,\n",
    "                                                                 file_name=file_name,\n",
    "                                                                 metric=soil_metric,\n",
    "                                                                 threshold=threshold))\n",
    "    \n",
    "# Compute\n",
    "print(len(delayed))\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dabf9b9d-af1f-42d4-af1d-e8bcd3efd05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2340\n",
      "CPU times: user 4.34 s, sys: 69.2 ms, total: 4.41 s\n",
      "Wall time: 4.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "soil_metric = \"5dmax-change\"\n",
    "threshold = None\n",
    "\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Get simulations\n",
    "file_names = os.listdir(f\"{project_data_path}/projections/{subset_name}/out/{ensemble_name}/\")\n",
    "\n",
    "# Run it\n",
    "for file_name in file_names:\n",
    "    # Only take first member\n",
    "    model, member = file_name.split('_')[:2]\n",
    "    if member == list(loca_all[model].keys())[0]:\n",
    "        delayed.append(dask.delayed(calculate_soilMoist_metrics)(subset_name=subset_name,\n",
    "                                                                 ensemble_name=ensemble_name,\n",
    "                                                                 file_name=file_name,\n",
    "                                                                 metric=soil_metric,\n",
    "                                                                 threshold=threshold))\n",
    "    \n",
    "# Compute\n",
    "print(len(delayed))\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98952f48-9450-4804-b69a-ed65747ed398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2340\n",
      "CPU times: user 4.84 s, sys: 123 ms, total: 4.96 s\n",
      "Wall time: 5.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "soil_metric = \"mean-anom\"\n",
    "threshold = None\n",
    "\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Get simulations\n",
    "file_names = os.listdir(f\"{project_data_path}/projections/{subset_name}/out/{ensemble_name}/\")\n",
    "\n",
    "# Run it\n",
    "for file_name in file_names:\n",
    "    # Only take first member\n",
    "    model, member = file_name.split('_')[:2]\n",
    "    if member == list(loca_all[model].keys())[0]:\n",
    "        delayed.append(dask.delayed(calculate_soilMoist_metrics)(subset_name=subset_name,\n",
    "                                                                 ensemble_name=ensemble_name,\n",
    "                                                                 file_name=file_name,\n",
    "                                                                 metric=soil_metric,\n",
    "                                                                 threshold=threshold))\n",
    "    \n",
    "# Compute\n",
    "print(len(delayed))\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67aa5ae5-fe67-4cc8-ac61-c6604cb34643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2340\n",
      "CPU times: user 5.04 s, sys: 145 ms, total: 5.19 s\n",
      "Wall time: 5.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "soil_metric = \"5dmin-anom\"\n",
    "threshold = None\n",
    "\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Get simulations\n",
    "file_names = os.listdir(f\"{project_data_path}/projections/{subset_name}/out/{ensemble_name}/\")\n",
    "\n",
    "# Run it\n",
    "for file_name in file_names:\n",
    "    # Only take first member\n",
    "    model, member = file_name.split('_')[:2]\n",
    "    if member == list(loca_all[model].keys())[0]:\n",
    "        delayed.append(dask.delayed(calculate_soilMoist_metrics)(subset_name=subset_name,\n",
    "                                                                 ensemble_name=ensemble_name,\n",
    "                                                                 file_name=file_name,\n",
    "                                                                 metric=soil_metric,\n",
    "                                                                 threshold=threshold))\n",
    "    \n",
    "# Compute\n",
    "print(len(delayed))\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04f0dfa5-3903-4f58-81d1-8bb57c7a09c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2340\n",
      "CPU times: user 4.63 s, sys: 117 ms, total: 4.75 s\n",
      "Wall time: 4.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "soil_metric = \"5dmax-anom\"\n",
    "threshold = None\n",
    "\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Get simulations\n",
    "file_names = os.listdir(f\"{project_data_path}/projections/{subset_name}/out/{ensemble_name}/\")\n",
    "\n",
    "# Run it\n",
    "for file_name in file_names:\n",
    "    # Only take first member\n",
    "    model, member = file_name.split('_')[:2]\n",
    "    if member == list(loca_all[model].keys())[0]:\n",
    "        delayed.append(dask.delayed(calculate_soilMoist_metrics)(subset_name=subset_name,\n",
    "                                                                 ensemble_name=ensemble_name,\n",
    "                                                                 file_name=file_name,\n",
    "                                                                 metric=soil_metric,\n",
    "                                                                 threshold=threshold))\n",
    "    \n",
    "# Compute\n",
    "print(len(delayed))\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84984f30-abc6-4d5b-a744-db249df1d1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2340\n",
      "CPU times: user 8min 14s, sys: 33.9 s, total: 8min 48s\n",
      "Wall time: 1h 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "soil_metric = \"mean\"\n",
    "threshold = None\n",
    "\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Get simulations\n",
    "file_names = os.listdir(f\"{project_data_path}/projections/{subset_name}/out/{ensemble_name}/\")\n",
    "\n",
    "# Run it\n",
    "for file_name in file_names:\n",
    "    # Only take first member\n",
    "    model, member = file_name.split('_')[:2]\n",
    "    if member == list(loca_all[model].keys())[0]:\n",
    "        delayed.append(dask.delayed(calculate_soilMoist_metrics)(subset_name=subset_name,\n",
    "                                                                 ensemble_name=ensemble_name,\n",
    "                                                                 file_name=file_name,\n",
    "                                                                 metric=soil_metric,\n",
    "                                                                 threshold=threshold))\n",
    "    \n",
    "# Compute\n",
    "print(len(delayed))\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e38de9f-c935-47e4-a139-14cc5dbdb76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2340\n",
      "CPU times: user 11min 18s, sys: 45.1 s, total: 12min 3s\n",
      "Wall time: 1h 30min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "soil_metric = \"5dmin\"\n",
    "threshold = None\n",
    "\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Get simulations\n",
    "file_names = os.listdir(f\"{project_data_path}/projections/{subset_name}/out/{ensemble_name}/\")\n",
    "\n",
    "# Run it\n",
    "for file_name in file_names:\n",
    "    # Only take first member\n",
    "    model, member = file_name.split('_')[:2]\n",
    "    if member == list(loca_all[model].keys())[0]:\n",
    "        delayed.append(dask.delayed(calculate_soilMoist_metrics)(subset_name=subset_name,\n",
    "                                                                 ensemble_name=ensemble_name,\n",
    "                                                                 file_name=file_name,\n",
    "                                                                 metric=soil_metric,\n",
    "                                                                 threshold=threshold))\n",
    "    \n",
    "# Compute\n",
    "print(len(delayed))\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc5c67ce-9c18-4c9a-8e2c-b3a22842cdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2340\n",
      "CPU times: user 12min 29s, sys: 45.9 s, total: 13min 15s\n",
      "Wall time: 1h 22min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "soil_metric = \"5dmax\"\n",
    "threshold = None\n",
    "\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "\n",
    "# Get simulations\n",
    "file_names = os.listdir(f\"{project_data_path}/projections/{subset_name}/out/{ensemble_name}/\")\n",
    "\n",
    "# Run it\n",
    "for file_name in file_names:\n",
    "    # Only take first member\n",
    "    model, member = file_name.split('_')[:2]\n",
    "    if member == list(loca_all[model].keys())[0]:\n",
    "        delayed.append(dask.delayed(calculate_soilMoist_metrics)(subset_name=subset_name,\n",
    "                                                                 ensemble_name=ensemble_name,\n",
    "                                                                 file_name=file_name,\n",
    "                                                                 metric=soil_metric,\n",
    "                                                                 threshold=threshold))\n",
    "    \n",
    "# Compute\n",
    "print(len(delayed))\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d1f72c-c912-48a7-8df5-186b84aa8476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
