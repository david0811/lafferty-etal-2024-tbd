{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58728ec0-f35e-4ff7-aeb9-8cfa3bfead9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import dask\n",
    "\n",
    "from src.train import train_and_store\n",
    "from src.read_inputs import read_hindcast_inputs\n",
    "\n",
    "from utils.initial_params import initial_params\n",
    "from utils.param_bounds import params_lower, params_upper\n",
    "from utils.param_names import param_names\n",
    "from utils.global_paths import project_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ec9c503-2db7-4826-acce-f3f65e8df7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = np.load(\n",
    "        f\"{project_data_path}/WBM/calibration/eCONUS/SMAP/SMAP_validation.npy\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35f1f1c6-7cda-40e3-a9a2-011e83dc3ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317, 194, 2555)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d3f8010-883e-4190-a5c1-74fcee39aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = obs.reshape(317 * 194, 2555)\n",
    "nan_inds_obs = np.isnan(ys).any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be161724-3db3-4e94-8f75-e54bf1b46339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_inds_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad4c3832-38ec-4b9b-a28d-bd71657b1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_inds_obs_new = np.copy(nan_inds_obs)\n",
    "nan_inds_obs_new[0] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbe6904a-0cc6-4ac6-ac61-313f26133460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_inds_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed306b8c-aaad-478b-8d45-bdc54b962a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_inds_obs_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af0a0f6e-c6f8-47b7-8fc0-26b3d3b16183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_inds_obs_new + nan_inds_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6769dfcf-a99d-4528-8378-f9f7398fb65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-065a345e-dcbf-11ee-8d4e-00001029fe80</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.SLURMCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">SLURMCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">587064ee</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-c2e7f791-a0b5-43d0-a6c7-647a82a605f6</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.6.0.158:46375\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.6.0.158:46375' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "### Dask ###\n",
    "############\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    # account=\"pches\",\n",
    "    account=\"open\",\n",
    "    cores=1,\n",
    "    memory=\"15GiB\",\n",
    "    walltime=\"01:00:00\"\n",
    ")\n",
    "cluster.scale(jobs=25)  # ask for jobs\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7849bfd0-5f4e-4402-8408-9fbc4cce6f0a",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbbfca15-2fec-4ca2-883d-75d8efc90cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of timeseries needed for quantile RMSE\n",
    "N = 2555\n",
    "\n",
    "##################################\n",
    "# Define all error functions\n",
    "##################################\n",
    "\n",
    "########## RMSE\n",
    "_rmse = lambda prediction, ys: jnp.sqrt(jnp.nanmean((prediction - ys) ** 2))\n",
    "\n",
    "########## MSE\n",
    "_mse = lambda prediction, ys: jnp.nanmean((prediction - ys) ** 2)\n",
    "\n",
    "########## KGE\n",
    "def _kge(prediction, ys):\n",
    "    corr = jnp.nanmean(\n",
    "        (prediction - jnp.nanmean(prediction)) * (ys - jnp.nanmean(ys))\n",
    "    ) / (jnp.nanstd(prediction) * jnp.nanstd(ys))\n",
    "    mean_ratio = jnp.nanmean(prediction) / jnp.nanmean(ys)\n",
    "    std_ratio = jnp.nanstd(prediction) / jnp.nanstd(ys)\n",
    "    kge = 1 - jnp.sqrt((corr - 1) ** 2 + (mean_ratio - 1) ** 2 + (std_ratio - 1) ** 2)\n",
    "    return -kge\n",
    "\n",
    "\n",
    "######### hollowRMSE\n",
    "size = round(N * 0.5)\n",
    "\n",
    "def _hollowrmse(prediction, ys):\n",
    "    q25 = jnp.quantile(ys, 0.25)\n",
    "    q75 = jnp.quantile(ys, 0.75)\n",
    "    inds = jnp.where((ys <= q25) | (ys >= q75), size=size)\n",
    "    prediction_q = prediction[inds]\n",
    "    ys_q = ys[inds]\n",
    "    return jnp.sqrt(jnp.nanmean((prediction_q - ys_q) ** 2))\n",
    "\n",
    "    \n",
    "# _error_fns = [_rmse, _mse, _kge, _hollowrmse]\n",
    "# error_fn_names = [\"rmse\", \"mse\", \"kge\", \"hollow-rmse\"]\n",
    "\n",
    "_error_fns = [_mse]\n",
    "error_fn_names = [\"mse\"]\n",
    "\n",
    "# ########## q0-25 RMSE\n",
    "# qmax = 0.25\n",
    "# size = round(N * qmax)\n",
    "\n",
    "# def _q25rmse(prediction, ys):\n",
    "#     thresh = jnp.quantile(ys, qmax)\n",
    "#     inds = jnp.where(ys <= thresh, size=size)\n",
    "#     prediction_q = prediction[inds]\n",
    "#     ys_q = ys[inds]\n",
    "#     return jnp.sqrt(jnp.nanmean((prediction_q - ys_q) ** 2))\n",
    "\n",
    "\n",
    "# ########## q75-100 RMSE\n",
    "# qmin = 0.75\n",
    "# size = round(N * qmin)\n",
    "\n",
    "# def _q75rmse(prediction, ys):\n",
    "#     thresh = jnp.quantile(ys, qmin)\n",
    "#     inds = jnp.where(ys >= thresh, size=size)\n",
    "#     prediction_q = prediction[inds]\n",
    "#     ys_q = ys[inds]\n",
    "#     return jnp.sqrt(jnp.nanmean((prediction_q - ys_q) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32517e8-66db-40c4-8810-8de7fe1071dc",
   "metadata": {},
   "source": [
    "## eCONUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2996e58-366f-4dff-8ce3-eacc7afddfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_name = \"eCONUS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad888d79-c493-4539-866d-b127eced7c5a",
   "metadata": {},
   "source": [
    "### SMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8df8531-13f2-4a64-8dbc-7d1cdc3d217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_name = \"SMAP\"\n",
    "\n",
    "# Read/perform train-test split\n",
    "val_frac = 0.2\n",
    "train_test_file = f'{project_data_path}/WBM/calibration/{subset_name}/{obs_name}/training_res/split_{str(val_frac)}.npz'   \n",
    "\n",
    "if os.path.exists(train_test_file):\n",
    "    npz = np.load(train_test_file)\n",
    "    val_inds_all = [npz[key] for key in npz.keys()]\n",
    "else:\n",
    "    ys, _, _, _ = read_hindcast_inputs(subset_name, obs_name, True)\n",
    "    Nspace = ys.shape[0]\n",
    "    Ntime = ys.shape[1]\n",
    "\n",
    "    # Get validation indices\n",
    "    val_inds_all = np.array_split(np.random.permutation(Nspace), 1/val_frac)\n",
    "\n",
    "    out_dict = dict([(str(i), val_inds_all[i]) for i in range(len(val_inds_all))])\n",
    "    np.savez(train_test_file, **out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "669c25ea-f007-44b8-97d9-89f0081953f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 56s, sys: 13.5 s, total: 3min 10s\n",
      "Wall time: 36min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "    \n",
    "# Random starting paramters\n",
    "n_random_starts = 5\n",
    "\n",
    "for _ in range(n_random_starts):\n",
    "    # Loop through loss functions\n",
    "    for _error_fn, error_fn_name in zip(_error_fns, error_fn_names):\n",
    "        # Loop through validation splits\n",
    "        for val_inds in val_inds_all:\n",
    "            # Generate starting params\n",
    "            initial_params = np.random.uniform(params_lower, params_upper)\n",
    "            # Hyperparameter adjustments to improve stability\n",
    "            if error_fn_name == \"kge\":\n",
    "                reg_const = 0.001\n",
    "            elif error_fn_name == 'mse':\n",
    "                reg_const = 0.1\n",
    "            else:\n",
    "                reg_const = 0.01\n",
    "\n",
    "            # Append delayed\n",
    "            delayed.append(\n",
    "                dask.delayed(train_and_store)(\n",
    "                    subset_name = subset_name,\n",
    "                    obs_name = obs_name,\n",
    "                    _error_fn = _error_fn,\n",
    "                    error_fn_name = error_fn_name,\n",
    "                    initial_theta = initial_params,\n",
    "                    params_lower = params_lower,\n",
    "                    params_upper = params_upper,\n",
    "                    param_names = param_names,\n",
    "                    val_inds = val_inds,\n",
    "                    reg_const = reg_const,\n",
    "                )\n",
    "            )\n",
    "\n",
    "# Compute\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542b5e6a-20f6-48a8-a30d-e5cf276e96e5",
   "metadata": {},
   "source": [
    "### VIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d0bbe02-94db-4487-a0fb-89f842c06e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_name = \"VIC\"\n",
    "\n",
    "# Read/perform train-test split\n",
    "val_frac = 0.2\n",
    "train_test_file = f'{project_data_path}/WBM/calibration/{subset_name}/{obs_name}/training_res/split_{str(val_frac)}.npz'   \n",
    "\n",
    "if os.path.exists(train_test_file):\n",
    "    npz = np.load(train_test_file)\n",
    "    val_inds_all = [npz[key] for key in npz.keys()]\n",
    "else:\n",
    "    ys, _, _, _ = read_hindcast_inputs(subset_name, obs_name, True)\n",
    "    Nspace = ys.shape[0]\n",
    "    Ntime = ys.shape[1]\n",
    "\n",
    "    # Get validation indices\n",
    "    val_inds_all = np.array_split(np.random.permutation(Nspace), 1/val_frac)\n",
    "\n",
    "    out_dict = dict([(str(i), val_inds_all[i]) for i in range(len(val_inds_all))])\n",
    "    np.savez(train_test_file, **out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74460f1d-b5ed-4f49-9575-4e87d92e19f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 15s, sys: 13.9 s, total: 2min 29s\n",
      "Wall time: 1h 44min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "    \n",
    "# Random starting paramters\n",
    "n_random_starts = 5\n",
    "\n",
    "for _ in range(n_random_starts):\n",
    "    # Loop through loss functions\n",
    "    for _error_fn, error_fn_name in zip(_error_fns, error_fn_names):\n",
    "        # Loop through validation splits\n",
    "        for val_inds in val_inds_all:\n",
    "            # Generate starting params\n",
    "            initial_params = np.random.uniform(params_lower, params_upper)\n",
    "            # Hyperparameter adjustments to improve stability\n",
    "            if error_fn_name == \"kge\":\n",
    "                reg_const = 0.001\n",
    "            else:\n",
    "                reg_const = 0.01\n",
    "            if error_fn_name == 'mse':\n",
    "                learning_rate = 1e-3\n",
    "            else:\n",
    "                learning_rate = 1e-2\n",
    "\n",
    "            # Append delayed\n",
    "            delayed.append(\n",
    "                dask.delayed(train_and_store)(\n",
    "                    subset_name = subset_name,\n",
    "                    obs_name = obs_name,\n",
    "                    _error_fn = _error_fn,\n",
    "                    error_fn_name = error_fn_name,\n",
    "                    initial_theta = initial_params,\n",
    "                    params_lower = params_lower,\n",
    "                    params_upper = params_upper,\n",
    "                    param_names = param_names,\n",
    "                    val_inds = val_inds,\n",
    "                    learning_rate = learning_rate,\n",
    "                    reg_const = reg_const,\n",
    "                )\n",
    "            )\n",
    "\n",
    "# Compute\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c587c0bb-3711-4714-92f8-1056713d1e4c",
   "metadata": {},
   "source": [
    "### NOAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fdd9e5c-5298-4270-b030-424f6fe390ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_name = \"NOAH\"\n",
    "\n",
    "# Read/perform train-test split\n",
    "val_frac = 0.2\n",
    "train_test_file = f'{project_data_path}/WBM/calibration/{subset_name}/{obs_name}/training_res/split_{str(val_frac)}.npz'   \n",
    "\n",
    "if os.path.exists(train_test_file):\n",
    "    npz = np.load(train_test_file)\n",
    "    val_inds_all = [npz[key] for key in npz.keys()]\n",
    "else:\n",
    "    ys, _, _, _ = read_hindcast_inputs(subset_name, obs_name, True)\n",
    "    Nspace = ys.shape[0]\n",
    "    Ntime = ys.shape[1]\n",
    "\n",
    "    # Get validation indices\n",
    "    val_inds_all = np.array_split(np.random.permutation(Nspace), 1/val_frac)\n",
    "\n",
    "    out_dict = dict([(str(i), val_inds_all[i]) for i in range(len(val_inds_all))])\n",
    "    np.savez(train_test_file, **out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20bbcdf6-29ce-42fb-b378-135702133b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 9s, sys: 13.2 s, total: 2min 22s\n",
      "Wall time: 1h 41min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "    \n",
    "# Random starting paramters\n",
    "n_random_starts = 5\n",
    "\n",
    "for _ in range(n_random_starts):\n",
    "    # Loop through loss functions\n",
    "    for _error_fn, error_fn_name in zip(_error_fns, error_fn_names):\n",
    "        # Loop through validation splits\n",
    "        for val_inds in val_inds_all:\n",
    "            # Generate starting params\n",
    "            initial_params = np.random.uniform(params_lower, params_upper)\n",
    "            # Hyperparameter adjustments to improve stability\n",
    "            if error_fn_name == \"kge\":\n",
    "                reg_const = 0.001\n",
    "            else:\n",
    "                reg_const = 0.01\n",
    "            if error_fn_name == 'mse':\n",
    "                learning_rate = 1e-3\n",
    "            else:\n",
    "                learning_rate = 1e-2\n",
    "\n",
    "            # Append delayed\n",
    "            delayed.append(\n",
    "                dask.delayed(train_and_store)(\n",
    "                    subset_name = subset_name,\n",
    "                    obs_name = obs_name,\n",
    "                    _error_fn = _error_fn,\n",
    "                    error_fn_name = error_fn_name,\n",
    "                    initial_theta = initial_params,\n",
    "                    params_lower = params_lower,\n",
    "                    params_upper = params_upper,\n",
    "                    param_names = param_names,\n",
    "                    val_inds = val_inds,\n",
    "                    learning_rate = learning_rate,\n",
    "                    reg_const = reg_const,\n",
    "                )\n",
    "            )\n",
    "\n",
    "# Compute\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aaef35-b239-4aba-8409-782f3e4936bb",
   "metadata": {},
   "source": [
    "### MOSAIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a120287e-0c06-43f0-ada2-ff5a86f3a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_name = \"MOSAIC\"\n",
    "\n",
    "# Read/perform train-test split\n",
    "val_frac = 0.2\n",
    "train_test_file = f'{project_data_path}/WBM/calibration/{subset_name}/{obs_name}/training_res/split_{str(val_frac)}.npz'   \n",
    "\n",
    "if os.path.exists(train_test_file):\n",
    "    npz = np.load(train_test_file)\n",
    "    val_inds_all = [npz[key] for key in npz.keys()]\n",
    "else:\n",
    "    ys, _, _, _ = read_hindcast_inputs(subset_name, obs_name, True)\n",
    "    Nspace = ys.shape[0]\n",
    "    Ntime = ys.shape[1]\n",
    "\n",
    "    # Get validation indices\n",
    "    val_inds_all = np.array_split(np.random.permutation(Nspace), 1/val_frac)\n",
    "\n",
    "    out_dict = dict([(str(i), val_inds_all[i]) for i in range(len(val_inds_all))])\n",
    "    np.savez(train_test_file, **out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58fa1df9-ff19-4164-aae2-77f1d7fbbd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 57s, sys: 13.2 s, total: 2min 10s\n",
      "Wall time: 1h 40min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "    \n",
    "# Random starting paramters\n",
    "n_random_starts = 5\n",
    "\n",
    "for _ in range(n_random_starts):\n",
    "    # Loop through loss functions\n",
    "    for _error_fn, error_fn_name in zip(_error_fns, error_fn_names):\n",
    "        # Loop through validation splits\n",
    "        for val_inds in val_inds_all:\n",
    "            # Generate starting params\n",
    "            initial_params = np.random.uniform(params_lower, params_upper)\n",
    "            # Hyperparameter adjustments to improve stability\n",
    "            if error_fn_name == \"kge\":\n",
    "                reg_const = 0.001\n",
    "            else:\n",
    "                reg_const = 0.01\n",
    "            if error_fn_name == 'mse':\n",
    "                learning_rate = 1e-3\n",
    "            else:\n",
    "                learning_rate = 1e-2\n",
    "\n",
    "            # Append delayed\n",
    "            delayed.append(\n",
    "                dask.delayed(train_and_store)(\n",
    "                    subset_name = subset_name,\n",
    "                    obs_name = obs_name,\n",
    "                    _error_fn = _error_fn,\n",
    "                    error_fn_name = error_fn_name,\n",
    "                    initial_theta = initial_params,\n",
    "                    params_lower = params_lower,\n",
    "                    params_upper = params_upper,\n",
    "                    param_names = param_names,\n",
    "                    val_inds = val_inds,\n",
    "                    learning_rate = learning_rate,\n",
    "                    reg_const = reg_const,\n",
    "                )\n",
    "            )\n",
    "\n",
    "# Compute\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6239aae2-7069-464f-9872-abefa92adb16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
