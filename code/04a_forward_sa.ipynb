{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac40b5b-e773-4a61-872e-6260a1391095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "from functools import reduce \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import dask\n",
    "\n",
    "from SALib.analyze import delta\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "plt.rcParams[\"font.sans-serif\"] = \"Arial\"\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42\n",
    "plt.rcParams[\"axes.linewidth\"] = 1.50\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "\n",
    "cm_data = np.loadtxt(\"./utils/colormaps/batlow.txt\")[::-1]\n",
    "sc_cmap = LinearSegmentedColormap.from_list(\"cmap\", cm_data, N=10)\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "from utils.global_paths import project_data_path, project_code_path, loca_path\n",
    "from utils.constants import obs_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3afc84ba-101a-4a5a-92ce-18cf0bbcf7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-b16ad4db-84c4-11ef-8eed-00000321fe80</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.SLURMCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">SLURMCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">a61a921e</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-97245395-db34-4043-8c3e-7c1d44e7b410</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.6.0.155:37407\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.6.0.155:37407' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "### Dask ###\n",
    "############\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    # account=\"pches\",\n",
    "    account=\"open\",\n",
    "    cores=1,\n",
    "    memory=\"30GiB\",\n",
    "    walltime=\"06:00:00\"\n",
    ")\n",
    "cluster.scale(jobs=20)  # ask for jobs\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4491cd1f-8174-4c02-9fad-acafcb4ae040",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b58cd59-dbd8-4775-9695-b1efdc14eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info \n",
    "subset_name = 'eCONUS'\n",
    "\n",
    "# Metrics\n",
    "soil_metrics_raw = ['mean', '5dmin', '5dmax']\n",
    "soil_metrics_change = ['mean-change', '5dmin-change', '5dmax-change']\n",
    "\n",
    "# Soil labels for plots\n",
    "soil_labels = {\"mean-anom\": \"Annual Average \\nSoil Moisture Anomaly\", \n",
    "               \"5dmin-anom\": \"Soil Moisture Anomaly \\nDuring Driest 5 Days\",\n",
    "               \"5dmax-anom\": \"Soil Moisture Anomaly \\nDuring Wettest 5 Days\",\n",
    "               \"mean-change\": \"Annual Average \\nSoil Moisture Change\", \n",
    "               \"5dmin-change\": \"Soil Moisture Change \\nDuring Driest 5 Days\",\n",
    "               \"5dmax-change\": \"Soil Moisture Change \\nDuring Wettest 5 Days\",\n",
    "               \"mean\": \"Annual Average \\nSoil Moisture\", \n",
    "               \"5dmin\": \"Soil Moisture \\nDuring Driest 5 Days\",\n",
    "               \"5dmax\": \"Soil Moisture \\nDuring Wettest 5 Days\"}\n",
    "\n",
    "# Time slices to analyze\n",
    "time_slices = [[2030, 2039], [2050,2059], [2080,2089]]\n",
    "\n",
    "# SSPs\n",
    "ssps = ['ssp245', 'ssp370']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "155d38dd-43ff-4356-9881-a20bb0f140bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# models: 27\n",
      "# model/expts: 99\n",
      "# model/expts/ens: 329\n",
      "# model/expts/ens (not including historical): 221\n"
     ]
    }
   ],
   "source": [
    "# Models \n",
    "models = os.listdir(f\"{loca_path}/\")\n",
    "models.remove('training_data')\n",
    "models.remove('scripts')\n",
    "\n",
    "loca_all = {}\n",
    "\n",
    "# Loop through models\n",
    "for model in models:\n",
    "    loca_all[model] = {}\n",
    "    # Loop through members\n",
    "    members = os.listdir(f\"{loca_path}/{model}/0p0625deg/\")\n",
    "    for member in members:\n",
    "        # Append SSPs\n",
    "        ssps = os.listdir(f\"{loca_path}/{model}/0p0625deg/{member}/\")\n",
    "        loca_all[model][member] = ssps\n",
    "\n",
    "# Matches website (https://loca.ucsd.edu/loca-version-2-for-north-america-ca-jan-2023/) as of Jan 2023\n",
    "print(f\"# models: {len(models)}\")\n",
    "print(f\"# model/expts: {np.sum([len(np.unique([item for row in [loca_all[model][member] for member in loca_all[model].keys()] for item in row])) for model in models])}\")\n",
    "print(f\"# model/expts/ens: {np.sum([len(loca_all[model][ssp]) for model in models for ssp in loca_all[model]])}\")\n",
    "print(f\"# model/expts/ens (not including historical): {np.sum([len([ssp for ssp in loca_all[model][member] if ssp != 'historical']) for model in models for member in loca_all[model]])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ce2a4c-5536-4a26-b99e-e9a8a354a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all soil moisture metrics\n",
    "def read_all(subset_name, soil_metric, ssps):\n",
    "    # For all\n",
    "    ds_all = []\n",
    "\n",
    "    # Loop through models\n",
    "    for model in models:\n",
    "        # Take first member only\n",
    "        for member in list(loca_all[model].keys())[:1]:\n",
    "            # Loop through SSPs\n",
    "            for ssp in loca_all[model][member]:\n",
    "                if ssp in ssps:\n",
    "                    projection_id = f\"{model}_{member}_{ssp}\"\n",
    "                    ds_proj = []\n",
    "                    # Loop through obs\n",
    "                    for obs_name in obs_names:\n",
    "                        # Concat along loss metrics\n",
    "                        ds = xr.open_mfdataset(f\"{project_data_path}/projections/{subset_name}/metrics/{soil_metric}/{projection_id}_{obs_name}_*.nc\",\n",
    "                                                combine=\"nested\", concat_dim = \"loss_metric\")\n",
    "                        # Append\n",
    "                        ds_proj.append(ds)\n",
    "                    # Concat along obs\n",
    "                    ds_proj = xr.concat(ds_proj, dim=\"obs_name\")\n",
    "                    ds_all.append(ds_proj)\n",
    "                    \n",
    "    # Concat along climate\n",
    "    ds_all = xr.concat(ds_all, dim=\"projection_id\")\n",
    "\n",
    "    # Fix time dim\n",
    "    ds_all['time'] = ds_all['time'].dt.year\n",
    "\n",
    "    return ds_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7827e0-78d2-43a0-aba2-3624fb76856b",
   "metadata": {},
   "source": [
    "# Delta SA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1ee0f0-f23e-4e68-a72a-8ec3addb0eb3",
   "metadata": {},
   "source": [
    "## Anomaly/changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57839a7a-029d-4b0f-b9ff-0986e52aaf62",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d51eb9ba-4875-47d3-807d-3eb882952887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads all .nc projections and stores as parquet file\n",
    "def store_as_df(subset_name, soil_metric, time_slice):\n",
    "    # Save path\n",
    "    save_path = f'{project_data_path}/projections/{subset_name}/metrics_df/{soil_metric}_{time_slice[0]}-{time_slice[1]}'\n",
    "    \n",
    "    # Check if done\n",
    "    if os.path.exists(save_path):\n",
    "        print(f'{soil_metric} {time_slice} already done!')\n",
    "    else:\n",
    "        # Read all (all SSPs)\n",
    "        ssps = ['ssp245', 'ssp370']\n",
    "        ds_all = read_all(subset_name, soil_metric, ssps)\n",
    "\n",
    "        # Select \n",
    "        vars_to_drop = ['projection_id', 'member', 'soil_id']\n",
    "        with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "            df = ds_all.sel(time=slice(time_slice[0], time_slice[1])).drop_vars(vars_to_drop).to_dask_dataframe()\n",
    "\n",
    "        # Store\n",
    "        df.to_parquet(save_path, append=False, overwrite=True, compute=True, write_index=False)\n",
    "        print(f'{soil_metric} {time_slice} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "160d3771-424a-46d4-81ef-f9be358cd69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read specified lat/lon and perfrom delta SA\n",
    "def get_delta(subset_name, soil_metric, time_slice, lat, lon, sa_factors):\n",
    "    # Read\n",
    "    sel = [(\"lat\", \"==\", lat), (\"lon\", \"==\", lon)]\n",
    "    file_path = f'{project_data_path}/projections/{subset_name}/metrics_df/{soil_metric}_{time_slice[0]}-{time_slice[1]}'\n",
    "    df_loc = pd.read_parquet(file_path, filters=sel, engine=\"pyarrow\")\n",
    "\n",
    "    # If needed\n",
    "    df_loc['soil_id'] = df_loc['obs_name'] + \"_\" + df_loc['loss_metric']\n",
    "\n",
    "    # Shuffle for good measure\n",
    "    df = df_loc.sample(frac=1)\n",
    "\n",
    "    # Skip if all NaN\n",
    "    if df.isnull().values.any():\n",
    "        return None\n",
    "\n",
    "    # Problem defn\n",
    "    n_factors = len(sa_factors)\n",
    "    problem = {\n",
    "        'num_vars': n_factors,\n",
    "        'names': sa_factors,\n",
    "    }\n",
    "\n",
    "    # Perform SA\n",
    "    X = df[sa_factors].to_numpy()\n",
    "    Y = df[soil_metric].to_numpy()\n",
    "    \n",
    "    Si = delta.analyze(problem, X, Y, num_resamples=2).to_df()\n",
    "    Si['lat'] = lat\n",
    "    Si['lon'] = lon\n",
    "\n",
    "    Si = Si.reset_index().pivot(index=['lat','lon'], columns='index', values='delta')\n",
    "    \n",
    "    return Si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d84999b0-cf3c-4276-9997-79cc84f7cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform gridpoint-level delta SA on saved parquet file\n",
    "def perform_delta_sa(subset_name, soil_metric, time_slice, sa_factors, save_name):\n",
    "    # Check if done\n",
    "    save_path = f'{project_data_path}/projections/{subset_name}/sa_results/{soil_metric}_{time_slice[0]}-{time_slice[1]}_delta-sa_{save_name}.nc'\n",
    "    if os.path.exists(save_path):\n",
    "        print(f'{soil_metric} {time_slice} already done!')\n",
    "        return None\n",
    "        \n",
    "    # Get non-NaN locs\n",
    "    locs = np.load(f\"{project_code_path}/code/utils/grids/{subset_name}_non_nans.npy\", allow_pickle=True)\n",
    "\n",
    "    # Loop over all with dask.delayed\n",
    "    delayed = []\n",
    "\n",
    "    for loc in locs:\n",
    "        lat, lon = loc\n",
    "        df_tmp = dask.delayed(get_delta)(subset_name, soil_metric, time_slice, lat, lon, sa_factors)\n",
    "        delayed.append(df_tmp)\n",
    "    \n",
    "    # Compute\n",
    "    delayed_out = dask.compute(*delayed)\n",
    "\n",
    "    # Pandas dataframe \n",
    "    df = pd.concat(delayed_out)\n",
    "    df = df.rename_axis(None, axis=1)\n",
    "\n",
    "    # Create a complete grid of lat, lon values\n",
    "    all_lats = np.load(f\"{project_code_path}/code/utils/grids/{subset_name}_lat.npy\")\n",
    "    all_lons = np.load(f\"{project_code_path}/code/utils/grids/{subset_name}_lon.npy\")\n",
    "\n",
    "    lon, lat = np.meshgrid(all_lons, all_lats)\n",
    "    lon_lat_index = pd.MultiIndex.from_arrays([lat.flatten(), lon.flatten()], names=['lat', 'lon'])\n",
    "\n",
    "    # Reindex to include all lat, lon combinations, filling missing ones with NaN\n",
    "    df_reindexed = df.reindex(lon_lat_index)\n",
    "\n",
    "    # Convert the reindexed DataFrame to an xarray Dataset\n",
    "    ds = xr.Dataset.from_dataframe(df_reindexed)\n",
    "\n",
    "    # Store\n",
    "    ds.to_netcdf(save_path)\n",
    "    print(f'{soil_metric} {time_slice} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "328cf365-724e-4a9c-b832-3e4354a827e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store non-nan coords for subset if not done already\n",
    "file_path = f\"{project_code_path}/code/utils/grids/{subset_name}_non_nans.npy\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    # Read all \n",
    "    ds_all = read_all(subset_name, soil_metrics[0], ssps)\n",
    "\n",
    "    # Get non-nans\n",
    "    ds_all_stacked = ds_all.stack(loc=['lat','lon']).isel(time=10, projection_id=10, obs_name=0, loss_metric=0)[soil_metrics[0]]\n",
    "    locs = ds_all_stacked[ds_all_stacked.notnull().compute()]['loc'].to_numpy()\n",
    "\n",
    "    # Save\n",
    "    np.save(file_path, locs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba44df8-6e16-438d-a07d-32900b22f580",
   "metadata": {},
   "source": [
    "### Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b557ba6-077c-4793-bb3e-eafe9466902f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-change [2030, 2039] done\n",
      "mean-change [2050, 2059] done\n",
      "mean-change [2080, 2089] done\n",
      "5dmin-change [2030, 2039] done\n",
      "5dmin-change [2050, 2059] done\n",
      "5dmin-change [2080, 2089] done\n",
      "5dmax-change [2030, 2039] done\n",
      "5dmax-change [2050, 2059] done\n",
      "5dmax-change [2080, 2089] done\n"
     ]
    }
   ],
   "source": [
    "# Store as df\n",
    "for soil_metric in soil_metrics_change:\n",
    "    for time_slice in time_slices:\n",
    "        store_as_df(subset_name, soil_metric, time_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "088d7a46-027a-4287-90ef-13d6a1339885",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:6\u001b[0m\n",
      "Cell \u001b[0;32mIn[11], line 29\u001b[0m, in \u001b[0;36mget_delta\u001b[0;34m(subset_name, soil_metric, time_slice, lat, lon, sa_factors)\u001b[0m\n\u001b[1;32m     26\u001b[0m X \u001b[38;5;241m=\u001b[39m df[sa_factors]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     27\u001b[0m Y \u001b[38;5;241m=\u001b[39m df[soil_metric]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m---> 29\u001b[0m Si \u001b[38;5;241m=\u001b[39m \u001b[43mdelta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_resamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_df()\n\u001b[1;32m     30\u001b[0m Si[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lat\n\u001b[1;32m     31\u001b[0m Si[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lon\n",
      "File \u001b[0;32m~/miniforge3/envs/climate-stack-2024-10/lib/python3.12/site-packages/SALib/analyze/delta.py:91\u001b[0m, in \u001b[0;36manalyze\u001b[0;34m(problem, X, Y, num_resamples, conf_level, print_to_console, seed, y_resamples, method)\u001b[0m\n\u001b[1;32m     89\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(y_resamples\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexp)), \u001b[38;5;241m48\u001b[39m)))\n\u001b[1;32m     90\u001b[0m m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, y_resamples, M \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 91\u001b[0m Ygrid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39mmax(Y), \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     93\u001b[0m keys \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelta_conf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS1_conf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m S \u001b[38;5;241m=\u001b[39m ResultDict((k, np\u001b[38;5;241m.\u001b[39mzeros(D)) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys)\n",
      "File \u001b[0;32m~/miniforge3/envs/climate-stack-2024-10/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3042\u001b[0m, in \u001b[0;36mmin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2925\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_min_dispatcher)\n\u001b[1;32m   2926\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2927\u001b[0m         where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2928\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2929\u001b[0m \u001b[38;5;124;03m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[1;32m   2930\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3040\u001b[0m \u001b[38;5;124;03m    6\u001b[39;00m\n\u001b[1;32m   3041\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3042\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3043\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/climate-stack-2024-10/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get non-NaN locs\n",
    "locs = np.load(f\"{project_code_path}/code/utils/grids/{subset_name}_non_nans.npy\", allow_pickle=True)\n",
    "\n",
    "for loc in locs[:1]:\n",
    "    lat, lon = loc\n",
    "    df_tmp = get_delta(subset_name, soil_metric, time_slice, lat, lon, sa_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc96475-5779-42f6-bf09-2189cc312ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read\n",
    "sel = [(\"lat\", \"==\", lat), (\"lon\", \"==\", lon)]\n",
    "file_path = f'{project_data_path}/projections/{subset_name}/metrics_df/{soil_metric}_{time_slice[0]}-{time_slice[1]}'\n",
    "df_loc = pd.read_parquet(file_path, filters=sel, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaeed04-de0e-43a0-9beb-27e29bc2731d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c8c8f66-9d13-48af-842b-b7fcb665c007",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean-change', '5dmin-change', '5dmax-change']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soil_metrics_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b86a7e8-ead7-4604-b2a8-2ed8ce029a6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:7\u001b[0m\n",
      "Cell \u001b[0;32mIn[12], line 21\u001b[0m, in \u001b[0;36mperform_delta_sa\u001b[0;34m(subset_name, soil_metric, time_slice, sa_factors, save_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m     delayed\u001b[38;5;241m.\u001b[39mappend(df_tmp)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Compute\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m delayed_out \u001b[38;5;241m=\u001b[39m \u001b[43mdask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdelayed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Pandas dataframe \u001b[39;00m\n\u001b[1;32m     24\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(delayed_out)\n",
      "File \u001b[0;32m~/miniforge3/envs/climate-stack-2024-10/lib/python3.12/site-packages/dask/base.py:660\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 660\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "Cell \u001b[0;32mIn[11], line 29\u001b[0m, in \u001b[0;36mget_delta\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m X \u001b[38;5;241m=\u001b[39m df[sa_factors]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     27\u001b[0m Y \u001b[38;5;241m=\u001b[39m df[soil_metric]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m---> 29\u001b[0m Si \u001b[38;5;241m=\u001b[39m delta\u001b[38;5;241m.\u001b[39manalyze(problem, X, Y, num_resamples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto_df()\n\u001b[1;32m     30\u001b[0m Si[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lat\n\u001b[1;32m     31\u001b[0m Si[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lon\n",
      "File \u001b[0;32m~/miniforge3/envs/climate-stack-2024-10/lib/python3.12/site-packages/SALib/analyze/delta.py:91\u001b[0m, in \u001b[0;36manalyze\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(y_resamples\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexp)), \u001b[38;5;241m48\u001b[39m)))\n\u001b[1;32m     90\u001b[0m m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, y_resamples, M \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 91\u001b[0m Ygrid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(np\u001b[38;5;241m.\u001b[39mmin(Y), np\u001b[38;5;241m.\u001b[39mmax(Y), \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     93\u001b[0m keys \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelta_conf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS1_conf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m S \u001b[38;5;241m=\u001b[39m ResultDict((k, np\u001b[38;5;241m.\u001b[39mzeros(D)) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys)\n",
      "File \u001b[0;32m~/miniforge3/envs/climate-stack-2024-10/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3042\u001b[0m, in \u001b[0;36mmin\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2925\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_min_dispatcher)\n\u001b[1;32m   2926\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2927\u001b[0m         where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2928\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2929\u001b[0m \u001b[38;5;124;03m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[1;32m   2930\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3040\u001b[0m \u001b[38;5;124;03m    6\u001b[39;00m\n\u001b[1;32m   3041\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3042\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapreduction(a, np\u001b[38;5;241m.\u001b[39mminimum, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out,\n\u001b[1;32m   3043\u001b[0m                           keepdims\u001b[38;5;241m=\u001b[39mkeepdims, initial\u001b[38;5;241m=\u001b[39minitial, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "File \u001b[0;32m~/miniforge3/envs/climate-stack-2024-10/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Perform SA\n",
    "for soil_metric in soil_metrics_change:\n",
    "    for time_slice in time_slices:\n",
    "        # All\n",
    "        sa_factors = ['ssp', 'model', 'time', 'obs_name', 'loss_metric']\n",
    "        save_name = 'all'\n",
    "        perform_delta_sa(subset_name, soil_metric, time_slice, sa_factors, save_name)\n",
    "    \n",
    "        # Soil grouped\n",
    "        sa_factors = ['ssp', 'model', 'time', 'soil_id']\n",
    "        save_name = 'soil_grouped'\n",
    "        perform_delta_sa(subset_name, soil_metric, time_slice, sa_factors, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7bdd3c-ac38-41e6-8c99-55f39504b373",
   "metadata": {},
   "source": [
    "## Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788c56a2-fcce-4a30-9ec6-66ea7483936c",
   "metadata": {},
   "source": [
    "### Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "617ac812-ab6c-4cf5-bf79-9754cda4ad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression function\n",
    "def linear_regression(X, y):\n",
    "    if np.isfinite(y).all() == False:\n",
    "        return np.array([np.nan, np.nan])\n",
    "    else:\n",
    "        return np.polyfit(X, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5eb40ae9-7e58-4469-9ec0-c49f8b7b141e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 45s, sys: 32 s, total: 3min 17s\n",
      "Wall time: 24min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SSPs\n",
    "ssps = ['ssp245', 'ssp370']\n",
    "\n",
    "# Loop through metrics\n",
    "for soil_metric in ['mean', '5dmin', '5dmax']:\n",
    "    # Check if done\n",
    "    save_path = f'{project_data_path}/projections/eCONUS/metrics/{soil_metric}_trend.nc'\n",
    "    if not os.path.exists(save_path):\n",
    "        # Real all\n",
    "        ds = read_all(subset_name, soil_metric, ssps)\n",
    "\n",
    "        # Linear trend\n",
    "        result = xr.apply_ufunc(\n",
    "            linear_regression,\n",
    "            ds['time'],  # input x data\n",
    "            ds[soil_metric],  # input y data\n",
    "            input_core_dims=[['time'], ['time']],  # specify core dimensions for inputs\n",
    "            output_core_dims=[['coef']],  # specify core dimensions for output\n",
    "            vectorize=True,  # apply function element-wise\n",
    "            dask='parallelized',  # enable parallelization with dask\n",
    "            output_dtypes=[float],  # specify output data type\n",
    "            dask_gufunc_kwargs={\"output_sizes\": {\"coef\": 2}},\n",
    "        ).compute()\n",
    "    \n",
    "        # Store\n",
    "        ds_result = xr.Dataset({'result': result})\n",
    "        ds_result['coef'] = ['trend', 'intcp']\n",
    "        ds_result.to_netcdf(save_path)\n",
    "    else:\n",
    "        print(f\"{soil_metric} already done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba19f89-965b-4833-9524-a6d2c4313276",
   "metadata": {},
   "source": [
    "### SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fbd2875-14b1-473a-be0b-74ec4448b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read specified lat/lon and perfrom delta SA\n",
    "def get_delta(ds, lat, lon, sa_factors):\n",
    "    # Select\n",
    "    df_loc = ds.sel(coef='trend').sel(lat=lat, lon=lon).to_dataframe().reset_index()\n",
    "\n",
    "    # If needed\n",
    "    df_loc['soil_id'] = df_loc['obs_name'] + \"_\" + df_loc['loss_metric']\n",
    "\n",
    "    # Shuffle for good measure\n",
    "    df = df_loc.sample(frac=1)\n",
    "\n",
    "    # Skip if all NaN\n",
    "    if df.isnull().values.any():\n",
    "        return None\n",
    "\n",
    "    # Problem defn\n",
    "    n_factors = len(sa_factors)\n",
    "    problem = {\n",
    "        'num_vars': n_factors,\n",
    "        'names': sa_factors,\n",
    "    }\n",
    "\n",
    "    # Perform SA\n",
    "    X = df[sa_factors].to_numpy()\n",
    "    Y = df['result'].to_numpy()\n",
    "    \n",
    "    Si = delta.analyze(problem, X, Y, num_resamples=2).to_df()\n",
    "    Si['lat'] = lat\n",
    "    Si['lon'] = lon\n",
    "\n",
    "    Si = Si.reset_index().pivot(index=['lat','lon'], columns='index', values='delta')\n",
    "    \n",
    "    return Si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68338952-8747-4fde-9c54-f55b410eeb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 7s, sys: 9.1 s, total: 5min 16s\n",
      "Wall time: 26min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Choose SA grouping\n",
    "# sa_factors = ['soil_id', 'ssp', 'model']\n",
    "# save_name = 'soil_grouped'\n",
    "\n",
    "sa_factors = ['ssp', 'model', 'obs_name', 'loss_metric']\n",
    "save_name = 'all'\n",
    "\n",
    "# Loop through metrics\n",
    "for soil_metric in ['mean', '5dmin', '5dmax']:\n",
    "    save_path = f'{project_data_path}/projections/{subset_name}/sa_results/{soil_metric}_trends_delta-sa_{save_name}.nc'\n",
    "    if os.path.exists(save_path):\n",
    "        print(f'{soil_metric} already done!')\n",
    "\n",
    "    else:\n",
    "        # Read trends\n",
    "        ds = xr.open_dataset(f'{project_data_path}/projections/{subset_name}/metrics/{soil_metric}_trend.nc')\n",
    "    \n",
    "        # Get non-NaN locs\n",
    "        locs = np.load(f\"{project_code_path}/code/utils/grids/{subset_name}_non_nans.npy\", allow_pickle=True)\n",
    "    \n",
    "        # Loop over all with dask.delayed\n",
    "        delayed = []\n",
    "        for loc in locs:\n",
    "            lat, lon = loc\n",
    "            df_tmp = dask.delayed(get_delta)(ds, lat, lon, sa_factors)\n",
    "            delayed.append(df_tmp)\n",
    "    \n",
    "        # Compute\n",
    "        delayed_out = dask.compute(*delayed)\n",
    "    \n",
    "        # Pandas dataframe \n",
    "        df = pd.concat(delayed_out)\n",
    "        df = df.rename_axis(None, axis=1)\n",
    "        \n",
    "        # Create a complete grid of lat, lon values\n",
    "        all_lats = np.load(f\"{project_code_path}/code/utils/grids/{subset_name}_lat.npy\")\n",
    "        all_lons = np.load(f\"{project_code_path}/code/utils/grids/{subset_name}_lon.npy\")\n",
    "        \n",
    "        lon, lat = np.meshgrid(all_lons, all_lats)\n",
    "        lon_lat_index = pd.MultiIndex.from_arrays([lat.flatten(), lon.flatten()], names=['lat', 'lon'])\n",
    "        \n",
    "        # Reindex to include all lat, lon combinations, filling missing ones with NaN\n",
    "        df_reindexed = df.reindex(lon_lat_index)\n",
    "        \n",
    "        # Convert the reindexed DataFrame to an xarray Dataset\n",
    "        ds_out = xr.Dataset.from_dataframe(df_reindexed)\n",
    "    \n",
    "        # Store\n",
    "        ds_out.to_netcdf(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa28f91b-277d-475c-97dc-f19a1e2451ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
