{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9384c76f-a951-4f90-a73f-d3106230bf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import regionmask\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "626b7594-9a8e-49ec-9f5d-a45a3469319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "#### Directories ####\n",
    "#####################\n",
    "nldas_path = '/storage/group/pches/default/public/NLDAS/'\n",
    "smap_path = '/storage/group/pches/default/public/SMAP/'\n",
    "project_data_path = '/storage/group/pches/default/users/dcl5300/wbm_soilM_crop_uc_lafferty-etal-2024-tbd_DATA'\n",
    "log_path = '/storage/home/dcl5300/work/current_projects/wbm_soilM_crop_uc_lafferty-etal-2024-tbd/code/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "052fa90a-0e0a-47ab-8661-15faf7157026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Function definitions\n",
    "#######################\n",
    "\n",
    "# Subsetting function\n",
    "def _subset_states(ds, list_of_states):\n",
    "    \"\"\"\n",
    "    Subsets a netCDF file to a list of states using regionmask\n",
    "    \"\"\"\n",
    "    if list_of_states == None:\n",
    "        return ds\n",
    "    # Subset\n",
    "    subset_index = regionmask.defined_regions.natural_earth_v5_0_0.us_states_50.map_keys(list_of_states)\n",
    "    subset_mask = regionmask.defined_regions.natural_earth_v5_0_0.us_states_50.mask(ds)\n",
    "    ds_subset = ds.where(subset_mask.isin(subset_index), drop=True)\n",
    "    # Return\n",
    "    return ds_subset\n",
    "\n",
    "# SMAP processing\n",
    "def process_smap(subset_name, list_of_states):\n",
    "    \"\"\"\n",
    "    Grabs SMAP outputs and stores as one netCDF file with after subsetting to list_of_states.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(f'{project_data_path}/WBM/calibration/{subset_name}/SMAP/SMAP_validation.nc'):\n",
    "        # Read all\n",
    "        files = glob(f'{smap_path}/processed_nldas_grid/SMAP_L4_SM_gph_all_nldas_*.nc')\n",
    "        ds_smap = xr.concat([_subset_states(xr.open_dataset(file)['sm_rootzone'], list_of_states) for file in files], dim='time')\n",
    "\n",
    "        # 365 day calendar\n",
    "        ds_smap = ds_smap.convert_calendar(calendar='noleap', dim='time')\n",
    "    \n",
    "        # Merge and store (and change units to kg/m3)\n",
    "        ds_out = xr.Dataset({'soilMoist':1000*ds_smap})\n",
    "        ds_out.attrs['units'] = 'kg/m3'\n",
    "        ds_out.to_netcdf(f'{project_data_path}/WBM/calibration/{subset_name}/SMAP/SMAP_validation.nc')\n",
    "\n",
    "        # Also store numpy array for quicker evaluations\n",
    "        npy_out = np.transpose(ds_out['soilMoist'].to_numpy(), (2,1,0))\n",
    "        np.save(f'{project_data_path}/WBM/calibration/{subset_name}/SMAP/SMAP_validation.npy', npy_out)\n",
    "    else:\n",
    "        print('SMAP already processed')\n",
    "\n",
    "# NLDAS processing\n",
    "def process_nldas(subset_name, list_of_states):\n",
    "    \"\"\"\n",
    "    Grabs NDLAS outputs and stores as one netCDF file with after subsetting to list_of_states.\n",
    "    \"\"\"\n",
    "    nldas_dict = {'VIC':'SOILM0_100cm', 'NOAH':'SOILM', 'MOSAIC':'SOILM'}\n",
    "    \n",
    "    # Loop through each\n",
    "    for model, var_id in nldas_dict.items():\n",
    "        if not os.path.isfile(f'{project_data_path}/WBM/calibration/{subset_name}/{model}/{model}_validation.nc'):\n",
    "            # Read all\n",
    "            files = glob(f'{nldas_path}/{model}/daily/*.nc')\n",
    "            ds_nldas = xr.concat([_subset_states(xr.open_dataset(file)[var_id], list_of_states) for file in files], dim='time')\n",
    "\n",
    "            # 365 day calendar\n",
    "            ds_nldas = ds_nldas.convert_calendar(calendar='noleap', dim='time')\n",
    "    \n",
    "            # Select correct depth\n",
    "            if model in ['MOSAIC', 'NOAH']:\n",
    "                ds_nldas = ds_nldas.isel(depth=1)\n",
    "            else:\n",
    "                ds_nldas = ds_nldas.isel(depth=0)\n",
    "        \n",
    "            # Merge and store\n",
    "            ds_out = xr.Dataset({'soilMoist':ds_nldas})\n",
    "            ds_out.attrs['units'] = 'kg/m3'\n",
    "            ds_out.to_netcdf(f'{project_data_path}/WBM/calibration/{subset_name}/{model}/{model}_validation.nc')\n",
    "\n",
    "            # Also store numpy array for quicker evaluations\n",
    "            npy_out = np.transpose(ds_out['soilMoist'].to_numpy(), (2,1,0))\n",
    "            np.save(f'{project_data_path}/WBM/calibration/{subset_name}/{model}/{model}_validation.npy', npy_out)\n",
    "\n",
    "# Forcing processing\n",
    "def process_forcing(subset_name, list_of_states):\n",
    "    \"\"\"\n",
    "    Grabs all forcing inputs are stores as single numpy npz file.\n",
    "    SMAP and NLDAS handled separately since meteo forcing is different. \n",
    "    \"\"\"\n",
    "    for obs in ['MOSAIC', 'NOAH', 'VIC', 'SMAP']:\n",
    "        if not os.path.isfile(f'{project_data_path}/WBM/calibration/{subset_name}/{obs}/inputs.npz'):\n",
    "            ######### Climate drivers\n",
    "            if obs == \"SMAP\":\n",
    "                files = glob(f'{smap_path}/processed_nldas_grid/SMAP_L4_SM_gph_all_nldas_*.nc')\n",
    "                ds_forcing = xr.concat([_subset_states(xr.open_dataset(file), list_of_states) for file in files], dim='time')\n",
    "            else:\n",
    "                files = glob(f'{nldas_path}/forcing/daily/NLDAS_FORA0125_H.A*.nc')\n",
    "                ds_forcing = xr.concat([_subset_states(xr.open_dataset(file), list_of_states) for file in files], dim='time')\n",
    "\n",
    "            # 365 day calendar\n",
    "            ds_forcing = ds_forcing.convert_calendar(calendar='noleap', dim='time')\n",
    "\n",
    "            # Numpy arrays in correct order (lon, lat, time)\n",
    "            if obs == \"SMAP\":\n",
    "                tas = np.transpose(ds_forcing['temp_lowatmmodlay'].to_numpy() - 273.15, (2,1,0))\n",
    "                prcp = np.transpose(ds_forcing['precipitation_total_surface_flux'].to_numpy() * 86400, (2,1,0))\n",
    "            else:\n",
    "                tas = np.transpose(ds_forcing['TMP'].to_numpy() - 273.15, (2,1,0))\n",
    "                prcp = np.transpose(ds_forcing['APCP'].to_numpy(), (2,1,0))\n",
    "\n",
    "            ############ Geophysical inputs\n",
    "            # Wilting point and awCap\n",
    "            ds_awCap = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/{obs}_awCap.nc'), list_of_states)\n",
    "            awCap = np.transpose(ds_awCap['awCap'].to_numpy())\n",
    "            \n",
    "            ds_wiltingp = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/{obs}_wiltingp.nc'), list_of_states)\n",
    "            wiltingp = np.transpose(ds_wiltingp['wiltingp'].to_numpy())\n",
    "\n",
    "            # Content fractions\n",
    "            ds_clayfrac = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/clayfrac_NLDASgrid.nc'), list_of_states)\n",
    "            ds_sandfrac = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/sandfrac_NLDASgrid.nc'), list_of_states)\n",
    "            ds_siltfrac = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/siltfrac_NLDASgrid.nc'), list_of_states)\n",
    "\n",
    "            clayfrac = np.transpose(ds_clayfrac['clayfrac'].to_numpy() / 100) # percentage -> fraction\n",
    "            sandfrac = np.transpose(ds_sandfrac['sandfrac'].to_numpy() / 100) # percentage -> fraction\n",
    "            siltfrac = np.transpose(ds_siltfrac['siltfrac'].to_numpy() / 100) # percentage -> fraction\n",
    "    \n",
    "            # Initial conditions\n",
    "            ds_init = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/calibration/{subset_name}/{obs}/{obs}_validation.nc'), list_of_states).isel(time=0)\n",
    "            soilMoist_init = np.transpose(ds_init['soilMoist'].to_numpy())\n",
    "            \n",
    "            # LAI\n",
    "            ds_lai = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/LAI_GLDAS_clima_NLDASgrid.nc'), list_of_states)\n",
    "            lai = np.transpose(ds_lai['LAI'].to_numpy(), (2,1,0))\n",
    "            \n",
    "            # Land properties\n",
    "            ds_land = _subset_states(xr.open_dataset(f\"{project_data_path}/WBM/geo_inputs/CDL-NLDAS_landtypes_NLDASgrid.nc\"), list_of_states)\n",
    "            corn = np.transpose(ds_land[\"corn\"].to_numpy())\n",
    "            cotton = np.transpose(ds_land[\"cotton\"].to_numpy())\n",
    "            rice = np.transpose(ds_land[\"rice\"].to_numpy())\n",
    "            sorghum = np.transpose(ds_land[\"sorghum\"].to_numpy())\n",
    "            soybeans = np.transpose(ds_land[\"soybeans\"].to_numpy())\n",
    "            durum_wheat = np.transpose(ds_land[\"durum_wheat\"].to_numpy())\n",
    "            spring_wheat = np.transpose(ds_land[\"spring_wheat\"].to_numpy())\n",
    "            winter_wheat = np.transpose(ds_land[\"winter_wheat\"].to_numpy())\n",
    "            cropland_other = np.transpose(ds_land[\"cropland_other\"].to_numpy())\n",
    "            water = np.transpose(ds_land[\"water\"].to_numpy())\n",
    "            evergreen_needleleaf = np.transpose(ds_land[\"evergreen_needleleaf\"].to_numpy())\n",
    "            evergreen_broadleaf = np.transpose(ds_land[\"evergreen_broadleaf\"].to_numpy())\n",
    "            deciduous_needleleaf = np.transpose(ds_land[\"deciduous_needleleaf\"].to_numpy())\n",
    "            deciduous_broadleaf = np.transpose(ds_land[\"deciduous_broadleaf\"].to_numpy())\n",
    "            mixed_forest = np.transpose(ds_land[\"mixed_forest\"].to_numpy())\n",
    "            woodland = np.transpose(ds_land[\"woodland\"].to_numpy())\n",
    "            wooded_grassland = np.transpose(ds_land[\"wooded_grassland\"].to_numpy())\n",
    "            closed_shurbland = np.transpose(ds_land[\"closed_shurbland\"].to_numpy())\n",
    "            open_shrubland = np.transpose(ds_land[\"open_shrubland\"].to_numpy())\n",
    "            grassland = np.transpose(ds_land[\"grassland\"].to_numpy())\n",
    "            barren = np.transpose(ds_land[\"barren\"].to_numpy())\n",
    "            urban = np.transpose(ds_land[\"urban\"].to_numpy())\n",
    "            \n",
    "            # Elevation properties\n",
    "            ds_elev = _subset_states(xr.open_dataset(f\"{project_data_path}/WBM/geo_inputs/NLDAS_elev_STD_NLDASgrid.nc\"), list_of_states)\n",
    "            elev_std = np.transpose(ds_elev['NLDAS_elev_std'].to_numpy())\n",
    "            \n",
    "            # Lat, Lon\n",
    "            lats = ds_lai.lat.to_numpy()\n",
    "            lons = ds_lai.lon.to_numpy()\n",
    "    \n",
    "            # Store numpy for easy access\n",
    "            np.savez(f'{project_data_path}/WBM/calibration/{subset_name}/{obs}/inputs.npz',\n",
    "                     tas=tas,\n",
    "                     prcp=prcp,\n",
    "                     lai=lai,\n",
    "                     awCap=awCap,\n",
    "                     wiltingp=wiltingp,\n",
    "                     corn=corn,\n",
    "                     cotton=cotton,\n",
    "                     rice=rice,\n",
    "                     sorghum=sorghum,\n",
    "                     soybeans=soybeans,\n",
    "                     durum_wheat=durum_wheat,\n",
    "                     spring_wheat=spring_wheat,\n",
    "                     winter_wheat=winter_wheat,\n",
    "                     cropland_other=cropland_other,\n",
    "                     water=water,\n",
    "                     evergreen_needleleaf=evergreen_needleleaf,\n",
    "                     evergreen_broadleaf=evergreen_broadleaf,\n",
    "                     deciduous_needleleaf=deciduous_needleleaf,\n",
    "                     deciduous_broadleaf=deciduous_broadleaf,\n",
    "                     mixed_forest=mixed_forest,\n",
    "                     woodland=woodland,\n",
    "                     wooded_grassland=wooded_grassland,\n",
    "                     closed_shurbland=closed_shurbland,\n",
    "                     open_shrubland=open_shrubland,\n",
    "                     grassland=grassland,\n",
    "                     barren=barren,\n",
    "                     urban=urban,\n",
    "                     clayfrac=clayfrac,\n",
    "                     sandfrac=sandfrac,\n",
    "                     siltfrac=siltfrac,\n",
    "                     elev_std=elev_std,\n",
    "                     lats=lats,\n",
    "                     lons=lons,\n",
    "                     soilMoist_init=soilMoist_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2177bdb-5160-4d31-af7c-4eb8e6f2b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forcing processing\n",
    "def process_forcing_vic(subset_name, list_of_states):\n",
    "    \"\"\"\n",
    "    Grabs all forcing inputs are stores as single numpy npz file.\n",
    "    SMAP and NLDAS handled separately since meteo forcing is different. \n",
    "    \"\"\"\n",
    "    obs = 'VIC'\n",
    "    if not os.path.isfile(f'{project_data_path}/WBM/calibration/{subset_name}/{obs}/inputs_SC.npz'):\n",
    "        ######### Climate drivers\n",
    "        files = glob(f'{nldas_path}/forcing/daily/NLDAS_FORA0125_H.A*.nc')\n",
    "        ds_forcing = xr.concat([_subset_states(xr.open_dataset(file), list_of_states) for file in files], dim='time')\n",
    "        \n",
    "        # 365 day calendar\n",
    "        ds_forcing = ds_forcing.convert_calendar(calendar='noleap', dim='time')\n",
    "        \n",
    "        # Numpy arrays in correct order (lon, lat, time)\n",
    "        tas = np.transpose(ds_forcing['TMP'].to_numpy() - 273.15, (2,1,0))\n",
    "        prcp = np.transpose(ds_forcing['APCP'].to_numpy(), (2,1,0))\n",
    "\n",
    "        ############ Geophysical inputs\n",
    "        # Soil types\n",
    "        ds_sand = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/NLDAS_sand.nc'), list_of_states)\n",
    "        sand = np.transpose(ds_sand['sand'].to_numpy())\n",
    "        \n",
    "        ds_loamy_sand = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/NLDAS_loamy_sand.nc'), list_of_states)\n",
    "        loamy_sand = np.transpose(ds_loamy_sand['loamy_sand'].to_numpy())\n",
    "        \n",
    "        ds_sandy_loam = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/NLDAS_sandy_loam.nc'), list_of_states)\n",
    "        sandy_loam = np.transpose(ds_sandy_loam['sandy_loam'].to_numpy())\n",
    "        \n",
    "        ds_silt_loam = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/NLDAS_silt_loam.nc'), list_of_states)\n",
    "        silt_loam = np.transpose(ds_silt_loam['silt_loam'].to_numpy())\n",
    "        \n",
    "        ds_silt = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/NLDAS_silt.nc'), list_of_states)\n",
    "        silt = np.transpose(ds_silt['silt'].to_numpy())\n",
    "        \n",
    "        ds_loam = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/NLDAS_loam.nc'), list_of_states)\n",
    "        loam = np.transpose(ds_loam['loam'].to_numpy())\n",
    "        \n",
    "        ds_sandy_clay_loam = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/NLDAS_sandy_clay_loam.nc'), list_of_states)\n",
    "        sandy_clay_loam = np.transpose(ds_sandy_clay_loam['sandy_clay_loam'].to_numpy())\n",
    "        \n",
    "        ds_silty_clay_loam = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/NLDAS_silty_clay_loam.nc'), list_of_states)\n",
    "        silty_clay_loam = np.transpose(ds_silty_clay_loam['silty_clay_loam'].to_numpy())\n",
    "        \n",
    "        ds_clay_loam = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/NLDAS_clay_loam.nc'), list_of_states)\n",
    "        clay_loam = np.transpose(ds_clay_loam['clay_loam'].to_numpy())\n",
    "        \n",
    "        ds_sandy_clay = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/NLDAS_sandy_clay.nc'), list_of_states)\n",
    "        sandy_clay = np.transpose(ds_sandy_clay['sandy_clay'].to_numpy())\n",
    "        \n",
    "        ds_silty_clay = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/NLDAS_silty_clay.nc'), list_of_states)\n",
    "        silty_clay = np.transpose(ds_silty_clay['silty_clay'].to_numpy())\n",
    "        \n",
    "        ds_clay = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/NLDAS_clay.nc'), list_of_states)\n",
    "        clay = np.transpose(ds_clay['clay'].to_numpy())\n",
    "\n",
    "        # Root Depth\n",
    "        ds_rootDepth = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/VIC_rootDepth.nc'), list_of_states)\n",
    "        rootDepth = np.transpose(ds_rootDepth['rootDepth'].to_numpy())\n",
    "        \n",
    "        # Content fractions\n",
    "        ds_clayfrac = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/clayfrac_NLDASgrid.nc'), list_of_states)\n",
    "        ds_sandfrac = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/sandfrac_NLDASgrid.nc'), list_of_states)\n",
    "        ds_siltfrac = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/siltfrac_NLDASgrid.nc'), list_of_states)\n",
    "        \n",
    "        clayfrac = np.transpose(ds_clayfrac['clayfrac'].to_numpy() / 100) # percentage -> fraction\n",
    "        sandfrac = np.transpose(ds_sandfrac['sandfrac'].to_numpy() / 100) # percentage -> fraction\n",
    "        siltfrac = np.transpose(ds_siltfrac['siltfrac'].to_numpy() / 100) # percentage -> fraction\n",
    "\n",
    "        # Initial conditions\n",
    "        ds_init = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/calibration/{subset_name}/{obs}/{obs}_validation.nc'), list_of_states).isel(time=0)\n",
    "        soilMoist_init = np.transpose(ds_init['soilMoist'].to_numpy())\n",
    "        \n",
    "        # LAI\n",
    "        ds_lai = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/LAI_GLDAS_clima_NLDASgrid.nc'), list_of_states)\n",
    "        lai = np.transpose(ds_lai['LAI'].to_numpy(), (2,1,0))\n",
    "            \n",
    "        # Land properties\n",
    "        ds_land = _subset_states(xr.open_dataset(f\"{project_data_path}/WBM/geo_inputs/CDL-NLDAS_landtypes_NLDASgrid.nc\"), list_of_states)\n",
    "        corn = np.transpose(ds_land[\"corn\"].to_numpy())\n",
    "        cotton = np.transpose(ds_land[\"cotton\"].to_numpy())\n",
    "        rice = np.transpose(ds_land[\"rice\"].to_numpy())\n",
    "        sorghum = np.transpose(ds_land[\"sorghum\"].to_numpy())\n",
    "        soybeans = np.transpose(ds_land[\"soybeans\"].to_numpy())\n",
    "        durum_wheat = np.transpose(ds_land[\"durum_wheat\"].to_numpy())\n",
    "        spring_wheat = np.transpose(ds_land[\"spring_wheat\"].to_numpy())\n",
    "        winter_wheat = np.transpose(ds_land[\"winter_wheat\"].to_numpy())\n",
    "        cropland_other = np.transpose(ds_land[\"cropland_other\"].to_numpy())\n",
    "        water = np.transpose(ds_land[\"water\"].to_numpy())\n",
    "        evergreen_needleleaf = np.transpose(ds_land[\"evergreen_needleleaf\"].to_numpy())\n",
    "        evergreen_broadleaf = np.transpose(ds_land[\"evergreen_broadleaf\"].to_numpy())\n",
    "        deciduous_needleleaf = np.transpose(ds_land[\"deciduous_needleleaf\"].to_numpy())\n",
    "        deciduous_broadleaf = np.transpose(ds_land[\"deciduous_broadleaf\"].to_numpy())\n",
    "        mixed_forest = np.transpose(ds_land[\"mixed_forest\"].to_numpy())\n",
    "        woodland = np.transpose(ds_land[\"woodland\"].to_numpy())\n",
    "        wooded_grassland = np.transpose(ds_land[\"wooded_grassland\"].to_numpy())\n",
    "        closed_shurbland = np.transpose(ds_land[\"closed_shurbland\"].to_numpy())\n",
    "        open_shrubland = np.transpose(ds_land[\"open_shrubland\"].to_numpy())\n",
    "        grassland = np.transpose(ds_land[\"grassland\"].to_numpy())\n",
    "        barren = np.transpose(ds_land[\"barren\"].to_numpy())\n",
    "        urban = np.transpose(ds_land[\"urban\"].to_numpy())\n",
    "            \n",
    "        # Elevation properties\n",
    "        ds_elev = _subset_states(xr.open_dataset(f\"{project_data_path}/WBM/geo_inputs/NLDAS_elev_STD_NLDASgrid.nc\"), list_of_states)\n",
    "        elev_std = np.transpose(ds_elev['NLDAS_elev_std'].to_numpy())\n",
    "            \n",
    "        # Lat, Lon\n",
    "        lats = ds_lai.lat.to_numpy()\n",
    "        lons = ds_lai.lon.to_numpy()\n",
    "    \n",
    "        # Store numpy for easy access\n",
    "        np.savez(f'{project_data_path}/WBM/calibration/{subset_name}/{obs}/inputs_SC.npz',\n",
    "                 tas=tas,\n",
    "                 prcp=prcp,\n",
    "                 lai=lai,\n",
    "                 sand = sand, \n",
    "                 loamy_sand = loamy_sand,\n",
    "                 sandy_loam = sandy_loam,\n",
    "                 silt_loam = silt_loam,\n",
    "                 silt = silt,\n",
    "                 loam = loam,\n",
    "                 sandy_clay_loam = sandy_clay_loam,\n",
    "                 silty_clay_loam = silty_clay_loam,\n",
    "                 clay_loam = clay_loam,\n",
    "                 sandy_clay = sandy_clay,\n",
    "                 silty_clay = silty_clay,\n",
    "                 clay = clay,\n",
    "                 rootDepth = rootDepth,\n",
    "                 corn=corn,\n",
    "                 cotton=cotton,\n",
    "                 rice=rice,\n",
    "                 sorghum=sorghum,\n",
    "                 soybeans=soybeans,\n",
    "                 durum_wheat=durum_wheat,\n",
    "                 spring_wheat=spring_wheat,\n",
    "                 winter_wheat=winter_wheat,\n",
    "                 cropland_other=cropland_other,\n",
    "                 water=water,\n",
    "                 evergreen_needleleaf=evergreen_needleleaf,\n",
    "                 evergreen_broadleaf=evergreen_broadleaf,\n",
    "                 deciduous_needleleaf=deciduous_needleleaf,\n",
    "                 deciduous_broadleaf=deciduous_broadleaf,\n",
    "                 mixed_forest=mixed_forest,\n",
    "                 woodland=woodland,\n",
    "                 wooded_grassland=wooded_grassland,\n",
    "                 closed_shurbland=closed_shurbland,\n",
    "                 open_shrubland=open_shrubland,\n",
    "                 grassland=grassland,\n",
    "                 barren=barren,\n",
    "                 urban=urban,\n",
    "                 clayfrac=clayfrac,\n",
    "                 sandfrac=sandfrac,\n",
    "                 siltfrac=siltfrac,\n",
    "                 elev_std=elev_std,\n",
    "                 lats=lats,\n",
    "                 lons=lons,\n",
    "                 soilMoist_init=soilMoist_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332416eb-c27b-406c-9408-cecafbde895d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Entire domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f39e22-2567-4676-b1e3-c91b36f1a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_name = \"CONUS\"\n",
    "list_of_states = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3042c557-36fc-42eb-8fbc-13fc79d729d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directories\n",
    "output_path = f\"{project_data_path}/WBM/precalibration/{subset_name}\"\n",
    "\n",
    "# Main\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(output_path)\n",
    "    \n",
    "# Subs\n",
    "for sub in [\"SMAP\", \"VIC\", \"NOAH\", \"MOSAIC\"]:\n",
    "    if not os.path.isdir(f\"{output_path}/{sub}\"):\n",
    "        os.mkdir(f\"{output_path}/{sub}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a2cf1e4-8408-49c1-80fc-1988e46c64e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAP already processed\n",
      "CPU times: user 694 µs, sys: 0 ns, total: 694 µs\n",
      "Wall time: 775 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SMAP\n",
    "process_smap(subset_name, list_of_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "966a8e81-2869-4960-8ce9-8ae9c7a27447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 1s, sys: 23.5 s, total: 1min 24s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NLDAS\n",
    "process_nldas(subset_name, list_of_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ca6e5b6-6457-4a3f-85f5-96b2ee365c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 18s, sys: 1min 3s, total: 4min 22s\n",
      "Wall time: 10min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Forcing\n",
    "process_forcing(subset_name, list_of_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946b761e-56e8-4f57-a936-b34893862375",
   "metadata": {},
   "source": [
    "### Central US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f63b04c-9d38-4c37-94d2-ed77dde23fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_name = \"centralUS\"\n",
    "list_of_states = [\"Illinois\", \"Iowa\", \"Wisconsin\", \"Minnesota\", \"North Dakota\", \"South Dakota\", \"Nebraska\", \"Kansas\", \"Missouri\", \"Indiana\", \"Ohio\", \"Michigan\", \"Kentucky\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9742308f-6e68-441d-a940-f4e1ba010d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directories\n",
    "output_path = f\"{project_data_path}/WBM/calibration/{subset_name}\"\n",
    "\n",
    "# Main\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(output_path)\n",
    "    \n",
    "# Subs\n",
    "for sub in [\"SMAP\", \"VIC\", \"NOAH\", \"MOSAIC\"]:\n",
    "    if not os.path.isdir(f\"{output_path}/{sub}\"):\n",
    "        os.mkdir(f\"{output_path}/{sub}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55a33927-3a0f-4d59-a5a5-5a2ae50f97f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAP already processed\n",
      "CPU times: user 781 µs, sys: 0 ns, total: 781 µs\n",
      "Wall time: 1.58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SMAP\n",
    "process_smap(subset_name, list_of_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aad8e47-54a7-4f7f-8450-9c17492f52aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 879 µs, sys: 192 µs, total: 1.07 ms\n",
      "Wall time: 2.77 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NLDAS\n",
    "process_nldas(subset_name, list_of_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48ae2e87-6e10-492f-acc4-75cb386e01de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 49s, sys: 6.95 s, total: 1min 56s\n",
      "Wall time: 2min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Forcing\n",
    "process_forcing(subset_name, list_of_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6226d09-167f-40e5-9b1d-1c6622acb325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d6698-85ac-471c-9e61-96c45915141a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d1a0b7-e258-4395-9c9f-7d9ae07464b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32c4480c-91b1-41da-ae02-d3ea4fb471f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 39s, sys: 5.28 s, total: 1min 44s\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# VIC forcing\n",
    "process_forcing_vic(subset_name, list_of_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd667c-f0f6-4ccb-864b-f003fd04e44c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
