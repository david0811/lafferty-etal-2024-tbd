{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9384c76f-a951-4f90-a73f-d3106230bf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import regionmask\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "626b7594-9a8e-49ec-9f5d-a45a3469319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "#### Directories ####\n",
    "#####################\n",
    "nldas_path = '/storage/group/pches/default/public/NLDAS/'\n",
    "smap_path = '/storage/group/pches/default/public/SMAP/'\n",
    "project_data_path = '/storage/group/pches/default/users/dcl5300/wbm_soilM_crop_uc_lafferty-etal-2024-tbd_DATA'\n",
    "log_path = '/storage/home/dcl5300/work/current_projects/wbm_soilM_crop_uc_lafferty-etal-2024-tbd/code/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "052fa90a-0e0a-47ab-8661-15faf7157026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Function definitions\n",
    "#######################\n",
    "\n",
    "# Subsetting function\n",
    "def _subset_states(ds, list_of_states):\n",
    "    \"\"\"\n",
    "    Subsets a netCDF file to a list of states using regionmask\n",
    "    \"\"\"\n",
    "    if list_of_states == None:\n",
    "        return ds\n",
    "    # Subset\n",
    "    subset_index = regionmask.defined_regions.natural_earth_v5_0_0.us_states_50.map_keys(list_of_states)\n",
    "    subset_mask = regionmask.defined_regions.natural_earth_v5_0_0.us_states_50.mask(ds)\n",
    "    ds_subset = ds.where(subset_mask.isin(subset_index), drop=True)\n",
    "    # Return\n",
    "    return ds_subset\n",
    "\n",
    "# SMAP processing\n",
    "def process_smap(subset_name, list_of_states):\n",
    "    \"\"\"\n",
    "    Grabs SMAP outputs and stores as one netCDF file with after subsetting to list_of_states.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(f'{project_data_path}/WBM/calibration/{subset_name}/SMAP/SMAP_validation.nc'):\n",
    "        # Read all\n",
    "        files = glob(f'{smap_path}/processed_nldas_grid/SMAP_L4_SM_gph_all_nldas_*.nc')\n",
    "        ds_smap = xr.concat([_subset_states(xr.open_dataset(file)['sm_rootzone'], list_of_states) for file in files], dim='time')\n",
    "\n",
    "        # 365 day calendar\n",
    "        ds_smap = ds_smap.convert_calendar(calendar='noleap', dim='time')\n",
    "    \n",
    "        # Merge and store (and change units to kg/m3)\n",
    "        ds_out = xr.Dataset({'soilMoist':1000*ds_smap})\n",
    "        ds_out.attrs['units'] = 'kg/m3'\n",
    "        ds_out.to_netcdf(f'{project_data_path}/WBM/calibration/{subset_name}/SMAP/SMAP_validation.nc')\n",
    "\n",
    "        # Also store numpy array for quicker evaluations\n",
    "        npy_out = np.transpose(ds_out['soilMoist'].to_numpy(), (2,1,0))\n",
    "        np.save(f'{project_data_path}/WBM/calibration/{subset_name}/SMAP/SMAP_validation.npy', npy_out)\n",
    "    else:\n",
    "        print('SMAP already processed')\n",
    "\n",
    "# NLDAS processing\n",
    "def process_nldas(subset_name, list_of_states):\n",
    "    \"\"\"\n",
    "    Grabs NDLAS outputs and stores as one netCDF file with after subsetting to list_of_states.\n",
    "    \"\"\"\n",
    "    nldas_dict = {'VIC':'SOILM0_100cm', 'NOAH':'SOILM', 'MOSAIC':'SOILM'}\n",
    "    \n",
    "    # Loop through each\n",
    "    for model, var_id in nldas_dict.items():\n",
    "        if not os.path.isfile(f'{project_data_path}/WBM/calibration/{subset_name}/{model}/{model}_validation.nc'):\n",
    "            # Read all\n",
    "            files = glob(f'{nldas_path}/{model}/daily/*.nc')\n",
    "            ds_nldas = xr.concat([_subset_states(xr.open_dataset(file)[var_id], list_of_states) for file in files], dim='time')\n",
    "\n",
    "            # 365 day calendar\n",
    "            ds_nldas = ds_nldas.convert_calendar(calendar='noleap', dim='time')\n",
    "    \n",
    "            # Select correct depth\n",
    "            if model in ['MOSAIC', 'NOAH']:\n",
    "                ds_nldas = ds_nldas.isel(depth=1)\n",
    "            else:\n",
    "                ds_nldas = ds_nldas.isel(depth=0)\n",
    "        \n",
    "            # Merge and store\n",
    "            ds_out = xr.Dataset({'soilMoist':ds_nldas})\n",
    "            ds_out.attrs['units'] = 'kg/m3'\n",
    "            ds_out.to_netcdf(f'{project_data_path}/WBM/calibration/{subset_name}/{model}/{model}_validation.nc')\n",
    "\n",
    "            # Also store numpy array for quicker evaluations\n",
    "            npy_out = np.transpose(ds_out['soilMoist'].to_numpy(), (2,1,0))\n",
    "            np.save(f'{project_data_path}/WBM/calibration/{subset_name}/{model}/{model}_validation.npy', npy_out)\n",
    "\n",
    "# Forcing processing\n",
    "def process_forcing(subset_name, list_of_states):\n",
    "    \"\"\"\n",
    "    Grabs all forcing inputs are stores as single numpy npz file.\n",
    "    SMAP and NLDAS handled separately since meteo forcing is different. \n",
    "    \"\"\"\n",
    "    for obs in ['MOSAIC', 'NOAH', 'VIC', 'SMAP']:\n",
    "        if not os.path.isfile(f'{project_data_path}/WBM/calibration/{subset_name}/{obs}/inputs.npz'):\n",
    "            ######### Climate drivers\n",
    "            if obs == \"SMAP\":\n",
    "                files = glob(f'{smap_path}/processed_nldas_grid/SMAP_L4_SM_gph_all_nldas_*.nc')\n",
    "                ds_forcing = xr.concat([_subset_states(xr.open_dataset(file), list_of_states) for file in files], dim='time')\n",
    "            else:\n",
    "                files = glob(f'{nldas_path}/forcing/daily/NLDAS_FORA0125_H.A*.nc')\n",
    "                ds_forcing = xr.concat([_subset_states(xr.open_dataset(file), list_of_states) for file in files], dim='time')\n",
    "\n",
    "            # 365 day calendar\n",
    "            ds_forcing = ds_forcing.convert_calendar(calendar='noleap', dim='time')\n",
    "\n",
    "            # Numpy arrays in correct order (lon, lat, time)\n",
    "            if obs == \"SMAP\":\n",
    "                tas = np.transpose(ds_forcing['temp_lowatmmodlay'].to_numpy() - 273.15, (2,1,0))\n",
    "                prcp = np.transpose(ds_forcing['precipitation_total_surface_flux'].to_numpy() * 86400, (2,1,0))\n",
    "            else:\n",
    "                tas = np.transpose(ds_forcing['TMP'].to_numpy() - 273.15, (2,1,0))\n",
    "                prcp = np.transpose(ds_forcing['APCP'].to_numpy(), (2,1,0))\n",
    "\n",
    "            ############ Geophysical inputs\n",
    "            # Wilting point and awCap\n",
    "            if obs == 'VIC': # VIC does not provide awCap, wiltingp, so use NOAH\n",
    "                obs_soilp = 'NOAH'\n",
    "            else:\n",
    "                obs_soilp = obs\n",
    "            \n",
    "            ds_awCap = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/{obs_soilp}_awCap.nc'), list_of_states)\n",
    "            awCap = np.transpose(ds_awCap['awCap'].to_numpy())\n",
    "            \n",
    "            ds_wiltingp = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/{obs_soilp}_wiltingp.nc'), list_of_states)\n",
    "            wiltingp = np.transpose(ds_wiltingp['wiltingp'].to_numpy())\n",
    "\n",
    "            # Content fractions\n",
    "            ds_clayfrac = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/clayfrac_NLDASgrid.nc'), list_of_states)\n",
    "            ds_sandfrac = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/sandfrac_NLDASgrid.nc'), list_of_states)\n",
    "            ds_siltfrac = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/siltfrac_NLDASgrid.nc'), list_of_states)\n",
    "\n",
    "            clayfrac = np.transpose(ds_clayfrac['clayfrac'].to_numpy() / 100) # percentage -> fraction\n",
    "            sandfrac = np.transpose(ds_sandfrac['sandfrac'].to_numpy() / 100) # percentage -> fraction\n",
    "            siltfrac = np.transpose(ds_siltfrac['siltfrac'].to_numpy() / 100) # percentage -> fraction\n",
    "    \n",
    "            # Initial conditions\n",
    "            ds_init = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/calibration/{subset_name}/{obs}/{obs}_validation.nc'), list_of_states).isel(time=0)\n",
    "            soilMoist_init = np.transpose(ds_init['soilMoist'].to_numpy())\n",
    "            \n",
    "            # LAI\n",
    "            ds_lai = _subset_states(xr.open_dataset(f'{project_data_path}/WBM/geo_inputs/LAI_GLDAS_clima_NLDASgrid.nc'), list_of_states)\n",
    "            lai = np.transpose(ds_lai['LAI'].to_numpy(), (2,1,0))\n",
    "            \n",
    "            # Land properties\n",
    "            ds_land = _subset_states(xr.open_dataset(f\"{project_data_path}/WBM/geo_inputs/CDL-NLDAS_landtypes_NLDASgrid.nc\"), list_of_states)\n",
    "            corn = np.transpose(ds_land[\"corn\"].to_numpy())\n",
    "            cotton = np.transpose(ds_land[\"cotton\"].to_numpy())\n",
    "            rice = np.transpose(ds_land[\"rice\"].to_numpy())\n",
    "            sorghum = np.transpose(ds_land[\"sorghum\"].to_numpy())\n",
    "            soybeans = np.transpose(ds_land[\"soybeans\"].to_numpy())\n",
    "            durum_wheat = np.transpose(ds_land[\"durum_wheat\"].to_numpy())\n",
    "            spring_wheat = np.transpose(ds_land[\"spring_wheat\"].to_numpy())\n",
    "            winter_wheat = np.transpose(ds_land[\"winter_wheat\"].to_numpy())\n",
    "            cropland_other = np.transpose(ds_land[\"cropland_other\"].to_numpy())\n",
    "            water = np.transpose(ds_land[\"water\"].to_numpy())\n",
    "            evergreen_needleleaf = np.transpose(ds_land[\"evergreen_needleleaf\"].to_numpy())\n",
    "            evergreen_broadleaf = np.transpose(ds_land[\"evergreen_broadleaf\"].to_numpy())\n",
    "            deciduous_needleleaf = np.transpose(ds_land[\"deciduous_needleleaf\"].to_numpy())\n",
    "            deciduous_broadleaf = np.transpose(ds_land[\"deciduous_broadleaf\"].to_numpy())\n",
    "            mixed_forest = np.transpose(ds_land[\"mixed_forest\"].to_numpy())\n",
    "            woodland = np.transpose(ds_land[\"woodland\"].to_numpy())\n",
    "            wooded_grassland = np.transpose(ds_land[\"wooded_grassland\"].to_numpy())\n",
    "            closed_shurbland = np.transpose(ds_land[\"closed_shurbland\"].to_numpy())\n",
    "            open_shrubland = np.transpose(ds_land[\"open_shrubland\"].to_numpy())\n",
    "            grassland = np.transpose(ds_land[\"grassland\"].to_numpy())\n",
    "            barren = np.transpose(ds_land[\"barren\"].to_numpy())\n",
    "            urban = np.transpose(ds_land[\"urban\"].to_numpy())\n",
    "            \n",
    "            # Elevation properties\n",
    "            ds_elev = _subset_states(xr.open_dataset(f\"{project_data_path}/WBM/geo_inputs/NLDAS_elev_STD_NLDASgrid.nc\"), list_of_states)\n",
    "            elev_std = np.transpose(ds_elev['NLDAS_elev_std'].to_numpy())\n",
    "            \n",
    "            # Lat, Lon\n",
    "            lats = ds_lai.lat.to_numpy()\n",
    "            lons = ds_lai.lon.to_numpy()\n",
    "    \n",
    "            # Store numpy for easy access\n",
    "            np.savez(f'{project_data_path}/WBM/calibration/{subset_name}/{obs}/inputs.npz',\n",
    "                     tas=tas,\n",
    "                     prcp=prcp,\n",
    "                     lai=lai,\n",
    "                     awCap=awCap,\n",
    "                     wiltingp=wiltingp,\n",
    "                     corn=corn,\n",
    "                     cotton=cotton,\n",
    "                     rice=rice,\n",
    "                     sorghum=sorghum,\n",
    "                     soybeans=soybeans,\n",
    "                     durum_wheat=durum_wheat,\n",
    "                     spring_wheat=spring_wheat,\n",
    "                     winter_wheat=winter_wheat,\n",
    "                     cropland_other=cropland_other,\n",
    "                     water=water,\n",
    "                     evergreen_needleleaf=evergreen_needleleaf,\n",
    "                     evergreen_broadleaf=evergreen_broadleaf,\n",
    "                     deciduous_needleleaf=deciduous_needleleaf,\n",
    "                     deciduous_broadleaf=deciduous_broadleaf,\n",
    "                     mixed_forest=mixed_forest,\n",
    "                     woodland=woodland,\n",
    "                     wooded_grassland=wooded_grassland,\n",
    "                     closed_shurbland=closed_shurbland,\n",
    "                     open_shrubland=open_shrubland,\n",
    "                     grassland=grassland,\n",
    "                     barren=barren,\n",
    "                     urban=urban,\n",
    "                     clayfrac=clayfrac,\n",
    "                     sandfrac=sandfrac,\n",
    "                     siltfrac=siltfrac,\n",
    "                     elev_std=elev_std,\n",
    "                     lats=lats,\n",
    "                     lons=lons,\n",
    "                     soilMoist_init=soilMoist_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332416eb-c27b-406c-9408-cecafbde895d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Entire domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f39e22-2567-4676-b1e3-c91b36f1a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_name = \"CONUS\"\n",
    "list_of_states = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3042c557-36fc-42eb-8fbc-13fc79d729d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directories\n",
    "output_path = f\"{project_data_path}/WBM/precalibration/{subset_name}\"\n",
    "\n",
    "# Main\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(output_path)\n",
    "    \n",
    "# Subs\n",
    "for sub in [\"SMAP\", \"VIC\", \"NOAH\", \"MOSAIC\"]:\n",
    "    if not os.path.isdir(f\"{output_path}/{sub}\"):\n",
    "        os.mkdir(f\"{output_path}/{sub}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a2cf1e4-8408-49c1-80fc-1988e46c64e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAP already processed\n",
      "CPU times: user 694 µs, sys: 0 ns, total: 694 µs\n",
      "Wall time: 775 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SMAP\n",
    "process_smap(subset_name, list_of_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "966a8e81-2869-4960-8ce9-8ae9c7a27447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 1s, sys: 23.5 s, total: 1min 24s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NLDAS\n",
    "process_nldas(subset_name, list_of_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ca6e5b6-6457-4a3f-85f5-96b2ee365c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 18s, sys: 1min 3s, total: 4min 22s\n",
      "Wall time: 10min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Forcing\n",
    "process_forcing(subset_name, list_of_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946b761e-56e8-4f57-a936-b34893862375",
   "metadata": {},
   "source": [
    "### Central US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f63b04c-9d38-4c37-94d2-ed77dde23fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_name = \"centralUS\"\n",
    "list_of_states = [\"Illinois\", \"Iowa\", \"Wisconsin\", \"Minnesota\", \"North Dakota\", \"South Dakota\", \"Nebraska\", \"Kansas\", \"Missouri\", \"Indiana\", \"Ohio\", \"Michigan\", \"Kentucky\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9742308f-6e68-441d-a940-f4e1ba010d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make directories\n",
    "output_path = f\"{project_data_path}/WBM/calibration/{subset_name}\"\n",
    "\n",
    "# Main\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(output_path)\n",
    "    \n",
    "# Subs\n",
    "for sub in [\"SMAP\", \"VIC\", \"NOAH\", \"MOSAIC\"]:\n",
    "    if not os.path.isdir(f\"{output_path}/{sub}\"):\n",
    "        os.mkdir(f\"{output_path}/{sub}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55a33927-3a0f-4d59-a5a5-5a2ae50f97f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 35s, sys: 16.2 s, total: 1min 52s\n",
      "Wall time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SMAP\n",
    "process_smap(subset_name, list_of_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aad8e47-54a7-4f7f-8450-9c17492f52aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 14s, sys: 26.4 s, total: 5min 40s\n",
      "Wall time: 9min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# NLDAS\n",
    "process_nldas(subset_name, list_of_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48ae2e87-6e10-492f-acc4-75cb386e01de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 23s, sys: 23 s, total: 6min 46s\n",
      "Wall time: 9min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Forcing\n",
    "process_forcing(subset_name, list_of_states)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
