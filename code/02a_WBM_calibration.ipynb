{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58728ec0-f35e-4ff7-aeb9-8cfa3bfead9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import optax\n",
    "\n",
    "import dask\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from water_balance_jax import wbm_jax, construct_Kpet_vec\n",
    "from initial_params import initial_params, initial_params_vic, constants\n",
    "from param_bounds import params_lower, params_upper, params_vic_lower, params_vic_upper\n",
    "from read_inputs import read_inputs, read_inputs\n",
    "from prediction import make_prediction, make_prediction_vic\n",
    "from global_paths import project_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6769dfcf-a99d-4528-8378-f9f7398fb65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-73a457fc-d037-11ee-a60e-00001029fe80</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_jobqueue.SLURMCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">SLURMCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">133fb01c</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-e7520489-cfc6-4ef9-aacf-70fdc99054c7</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.6.0.156:39569\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/proxy/8787/status\" target=\"_blank\">/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.6.0.156:39569' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "### Dask ###\n",
    "############\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    # account=\"pches\",\n",
    "    account=\"open\",\n",
    "    cores=1,\n",
    "    memory=\"5GiB\",\n",
    "    walltime=\"01:00:00\"\n",
    ")\n",
    "cluster.scale(jobs=30)  # ask for jobs\n",
    "\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a624d-541f-4495-b2dc-17d804a8b3c0",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90258cb5-f985-468b-8ca7-89e434f3f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_store(subset_name,\n",
    "                    obs_name,\n",
    "                    _error_fn,\n",
    "                    error_fn_name,\n",
    "                    param_names,\n",
    "                    n_epochs = 30,\n",
    "                    batch_size = 2**5,\n",
    "                    opt = 'adam',\n",
    "                    learning_rate = 1e-3,\n",
    "                    val_inds = None,\n",
    "                    reg_const = 0.001,\n",
    "                    initial_params = initial_params,\n",
    "                    params_lower = params_lower,\n",
    "                    params_upper = params_upper):\n",
    "    #############################################\n",
    "    # Loss function with correct error metric\n",
    "    ############################################\n",
    "    # Prediction loss\n",
    "    if obs_name == \"VIC\":\n",
    "        def prediction_loss(theta, constants,\n",
    "                            x_forcing_nt, x_forcing_nyrs, x_maps, ys):\n",
    "            prediction = make_prediction_vic(theta, constants, x_forcing_nt, x_forcing_nyrs, x_maps)\n",
    "        return _error_fn(prediction, ys)\n",
    "    else:\n",
    "        def prediction_loss(theta, constants,\n",
    "                            x_forcing_nt, x_forcing_nyrs, x_maps, ys):\n",
    "            prediction = make_prediction(theta, constants, x_forcing_nt, x_forcing_nyrs, x_maps)\n",
    "            return _error_fn(prediction, ys)\n",
    "    \n",
    "    # Regularization loss\n",
    "    def reg_loss(theta, initial_params, params_lower, params_upper):\n",
    "        return jnp.nansum((theta - initial_params)**2 / ((theta - params_lower) * (params_upper - theta)))\n",
    "    \n",
    "    # Total loss\n",
    "    def loss_fn(theta, reg_const, initial_params, params_lower, params_upper, constants,\n",
    "                x_forcing_nt, x_forcing_nyrs, x_maps, ys):\n",
    "        return prediction_loss(theta, constants, x_forcing_nt, x_forcing_nyrs, x_maps, ys) + \\\n",
    "                reg_const * reg_loss(theta, initial_params, params_lower, params_upper)\n",
    "    \n",
    "    # jit and vmap it\n",
    "    pred_loss_value = jax.jit(jax.vmap(prediction_loss, in_axes=(None, None, 0, 0, 0, 0), out_axes=0))\n",
    "    loss_value_and_grad = jax.jit(jax.vmap(jax.value_and_grad(loss_fn), in_axes=(None, None, None, None, None, None, 0, 0, 0, 0), out_axes=0))\n",
    "\n",
    "    ###########################\n",
    "    # Setup\n",
    "    ###########################\n",
    "    # Read data\n",
    "    ys, x_forcing_nt, x_forcing_nyrs, x_maps = read_inputs(subset_name, obs_name, True)\n",
    "    N = ys.shape[0]\n",
    "    \n",
    "    # Get train/val split over space\n",
    "    if len(val_inds) > 0:\n",
    "        ys_val, x_forcing_nt_val, x_forcing_nyrs_val, x_maps_val = ys[val_inds], x_forcing_nt[val_inds], x_forcing_nyrs[val_inds], x_maps[val_inds]\n",
    "        train_inds = np.array([n for n in np.arange(N) if n not in val_inds])\n",
    "        ys_train, x_forcing_nt_train, x_forcing_nyrs_train, x_maps_train = ys[train_inds], x_forcing_nt[train_inds], x_forcing_nyrs[train_inds], x_maps[train_inds]\n",
    "    else:\n",
    "        ys_train, x_forcing_nt_train, x_forcing_nyrs_train, x_maps_train = ys, x_forcing_nt, x_forcing_nyrs, x_maps\n",
    "    \n",
    "    # Define mini-batch hyper-parameters\n",
    "    N_train = ys_train.shape[0]\n",
    "    n_minibatches = 1 + N_train // batch_size\n",
    "\n",
    "    # Initial parameters\n",
    "    theta = np.random.uniform(low=params_lower, high=params_upper)\n",
    "    # theta = initial_params\n",
    "\n",
    "    # Optimizer\n",
    "    if opt == 'adam':\n",
    "        adam = optax.adam(learning_rate=learning_rate)\n",
    "        opt_fn = adam.update\n",
    "        opt_state = adam.init(theta)\n",
    "    elif opt == 'sgd':\n",
    "        learning_rate = 1e-5\n",
    "        opt_state = None\n",
    "        def sgd(gradients, state):\n",
    "            return -learning_rate * gradients, state\n",
    "        opt_fn = sgd\n",
    "\n",
    "    # Loss\n",
    "    train_loss_out = np.empty(n_epochs + 1)\n",
    "    pred_loss_out = np.empty(n_epochs + 1)\n",
    "    reg_loss_out = np.empty(n_epochs + 1)\n",
    "    val_loss_out = np.empty(n_epochs + 1)\n",
    "\n",
    "    # Where to store results\n",
    "    datetime_str = datetime.now().strftime('%Y%m%d-%H%M')\n",
    "    random_str = str(abs(theta[0])).replace('.','')[:5] # used to discern different starting values\n",
    "    training_name = f\"{error_fn_name}_{str(n_epochs)}epochs_{str(batch_size)}batchsize_{str(val_inds[0])}val_{str(reg_const)}reg_{random_str}r\"\n",
    "\n",
    "    out_file_path = f\"{project_data_path}/WBM/calibration/{subset_name}/{obs_name}/training_res/{training_name}.txt\"\n",
    "    f = open(out_file_path, \"w\")\n",
    "    f.write(f\"epoch metric train_loss pred_loss reg_loss val_loss {' '.join(param_names)}\\n\")\n",
    "\n",
    "    # initial results\n",
    "    pred_loss_init = jnp.mean(pred_loss_value(theta,\n",
    "                                              constants,\n",
    "                                              x_forcing_nt_train,\n",
    "                                              x_forcing_nyrs_train,\n",
    "                                              x_maps_train,\n",
    "                                              ys_train))\n",
    "    if len(val_inds) > 0:\n",
    "        val_loss_init = jnp.mean(pred_loss_value(theta,\n",
    "                                                 constants,\n",
    "                                                 x_forcing_nt_val,\n",
    "                                                 x_forcing_nyrs_val,\n",
    "                                                 x_maps_val,\n",
    "                                                 ys_val))\n",
    "    else:\n",
    "        val_loss_init = np.nan\n",
    "        \n",
    "    reg_loss_init = reg_loss(theta, initial_params, params_lower, params_upper)\n",
    "    print(f\"Epoch 0 pred loss: {pred_loss_init:.4f}, reg_loss: {reg_loss_init:.4f}, val loss: {val_loss_init:.4f}\")\n",
    "    \n",
    "    ###########################\n",
    "    # Training loop\n",
    "    ###########################\n",
    "    invalid_theta_count = 0 \n",
    "    \n",
    "    for epoch in range(n_epochs + 1):\n",
    "        # Shuffle indices\n",
    "        shuffled_inds = np.random.permutation(N_train)\n",
    "    \n",
    "        # Generate a mini-batch\n",
    "        minibatch_inds = [shuffled_inds[(i*batch_size):((i + 1)*batch_size)] for i in range(n_minibatches)]\n",
    "\n",
    "        # For batch loss\n",
    "        batch_loss = [None] * n_minibatches\n",
    "\n",
    "        for idx, inds in enumerate(minibatch_inds):\n",
    "            # Calculate gradient of loss function, update parameters\n",
    "            loss, grads = loss_value_and_grad(theta, reg_const, initial_params, params_lower, params_upper, constants,\n",
    "                                              x_forcing_nt_train[inds],\n",
    "                                              x_forcing_nyrs_train[inds],\n",
    "                                              x_maps_train[inds],\n",
    "                                              ys_train[inds])\n",
    "            updates, opt_state = opt_fn(jnp.nanmean(grads, axis=0), opt_state)\n",
    "            theta = optax.apply_updates(theta, updates)\n",
    "            batch_loss[idx] = loss\n",
    "            # Break if theta steps outside bounds\n",
    "            if (theta < params_lower).any() or (theta > params_upper).any():\n",
    "                print('Found invalid parameter... re-initializaing')\n",
    "                invalid_theta_count += 1\n",
    "                if invalid_theta_count > 5:\n",
    "                    f.close()\n",
    "                    # os.remove(out_file_path)\n",
    "                    return train_loss_out, pred_loss_out, reg_loss_out, val_loss_out, theta\n",
    "                else:\n",
    "                    theta = np.random.uniform(low=params_lower, high=params_upper)\n",
    "\n",
    "        # Save all losses\n",
    "        train_loss_out[epoch] = jnp.nanmean(jnp.array([item for row in batch_loss for item in row]))\n",
    "        reg_loss_out[epoch] = reg_loss(theta, initial_params, params_lower, params_upper)\n",
    "        pred_loss_out[epoch] = train_loss_out[epoch] - (reg_const * reg_loss_out[epoch])\n",
    "        if len(val_inds) > 0:\n",
    "            val_loss_out[epoch] = jnp.mean(pred_loss_value(theta,\n",
    "                                                          constants,\n",
    "                                                          x_forcing_nt_val,\n",
    "                                                          x_forcing_nyrs_val,\n",
    "                                                          x_maps_val,\n",
    "                                                          ys_val))\n",
    "        else:\n",
    "            val_loss_out[epoch] = jnp.nan\n",
    "        \n",
    "        # Write every epoch\n",
    "        theta_str = [str(param) for param in theta]\n",
    "        f.write(f\"{str(epoch + 1)} {error_fn_name} {train_loss_out[epoch]:.4f} {pred_loss_out[epoch]:.4f} {reg_loss_out[epoch]:.4f} {val_loss_out[epoch]:.4f} {' '.join(theta_str)}\\n\")\n",
    "        # Print every 5\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"Epoch {str(epoch + 1)} total loss: {train_loss_out[epoch]:.4f}, pred loss: {pred_loss_out[epoch]:.4f}, reg_loss: {reg_loss_out[epoch]:.4f}, val loss: {val_loss_out[epoch]:.4f}\")\n",
    "\n",
    "    f.close()\n",
    "    return train_loss_out, pred_loss_out, reg_loss_out, val_loss_out, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7849bfd0-5f4e-4402-8408-9fbc4cce6f0a",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbbfca15-2fec-4ca2-883d-75d8efc90cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of timeseries needed for quantile RMSE\n",
    "N = 2555\n",
    "\n",
    "# Define all error functions\n",
    "# RMSE\n",
    "_rmse = lambda prediction, ys: jnp.sqrt(jnp.nanmean((prediction-ys)**2))\n",
    "\n",
    "# MSE\n",
    "_mse = lambda prediction, ys: jnp.nanmean((prediction-ys)**2)\n",
    "\n",
    "# KGE\n",
    "def _kge(prediction, ys):\n",
    "    corr = jnp.nanmean((prediction - jnp.nanmean(prediction))*(ys - jnp.nanmean(ys))) / (jnp.nanstd(prediction) * jnp.nanstd(ys))\n",
    "    mean_ratio = jnp.nanmean(prediction) / jnp.nanmean(ys)\n",
    "    std_ratio = jnp.nanstd(prediction) / jnp.nanstd(ys)\n",
    "    kge = 1 - jnp.sqrt((corr - 1)**2 + (mean_ratio - 1)**2 + (std_ratio - 1)**2)\n",
    "    return -kge \n",
    "\n",
    "# q0-25 RMSE\n",
    "qmax = 0.25\n",
    "size = round(N * qmax)\n",
    "def _q25rmse(prediction, ys):\n",
    "    thresh = jnp.quantile(ys, qmax)\n",
    "    inds = jnp.where(ys <= thresh, size=size)\n",
    "    prediction_q = prediction[inds]\n",
    "    ys_q = ys[inds]\n",
    "    return jnp.sqrt(jnp.nanmean((prediction_q - ys_q)**2))\n",
    "\n",
    "# q75-100 RMSE\n",
    "qmin = 0.75\n",
    "size = round(N * qmin)\n",
    "def _q75rmse(prediction, ys):\n",
    "    thresh = jnp.quantile(ys, qmin)\n",
    "    inds = jnp.where(ys >= thresh, size=size)\n",
    "    prediction_q = prediction[inds]\n",
    "    ys_q = ys[inds]\n",
    "    return jnp.sqrt(jnp.nanmean((prediction_q - ys_q)**2))\n",
    "\n",
    "_error_fns = [_rmse, _mse, _kge, _q25rmse, _q75rmse]\n",
    "error_fn_names = ['rmse', 'mse', 'kge', 'q0-25rmse', 'q75-100rmse']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f746119c-d74f-4f54-a3d3-62809522617a",
   "metadata": {},
   "source": [
    "### NOAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d66c3bf2-ed26-4d19-bdde-66530af5c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info\n",
    "subset_name = 'centralUS'\n",
    "obs_name = 'NOAH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efa2c1fc-9f0b-45f1-9e72-e4dcb035f9f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rootDepth is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get dimensions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ys, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mread_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m Nspace \u001b[38;5;241m=\u001b[39m ys\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m Ntime \u001b[38;5;241m=\u001b[39m ys\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/storage/work/dcl5300/current_projects/wbm_soilM_crop_uc_lafferty-etal-2024-tbd/code/read_inputs.py:46\u001b[0m, in \u001b[0;36mread_inputs\u001b[0;34m(subset_name, obs_name, remove_nans)\u001b[0m\n\u001b[1;32m     43\u001b[0m sandfrac \u001b[38;5;241m=\u001b[39m npz[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msandfrac\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     44\u001b[0m siltfrac \u001b[38;5;241m=\u001b[39m npz[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msiltfrac\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 46\u001b[0m rootDepth \u001b[38;5;241m=\u001b[39m \u001b[43mnpz\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrootDepth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Land use\u001b[39;00m\n\u001b[1;32m     49\u001b[0m corn \u001b[38;5;241m=\u001b[39m npz[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/climate-stack-mamba-2023-12/lib/python3.11/site-packages/numpy/lib/npyio.py:263\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a file in the archive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rootDepth is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "# Get dimensions\n",
    "ys, _, _, _ = read_inputs(subset_name, obs_name, True)\n",
    "Nspace = ys.shape[0]\n",
    "Ntime = ys.shape[1]\n",
    "\n",
    "# Get validation indices\n",
    "val_frac = 0.2\n",
    "val_inds_all = np.array_split(np.random.permutation(Nspace), 1/val_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58ccef39-b939-40ad-b694-0cd667d7a9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 41s, sys: 27.7 s, total: 7min 8s\n",
      "Wall time: 51min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "\n",
    "for _error_fn, error_fn_name in zip(_error_fns, error_fn_names):\n",
    "    for _ in range(4):\n",
    "        for val_inds in val_inds_all:\n",
    "            delayed.append(dask.delayed(train_and_store)(subset_name = subset_name,\n",
    "                                                         obs_name = obs_name,\n",
    "                                                         _error_fn = _error_fn,\n",
    "                                                         error_fn_name = error_fn_name,\n",
    "                                                         val_inds = val_inds))\n",
    "\n",
    "_ = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b78298f-5adc-4abe-9c51-0e8d4699cc6e",
   "metadata": {},
   "source": [
    "### VIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b521f9df-98f6-48a2-aa33-a8c015979e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info\n",
    "subset_name = 'centralUS'\n",
    "obs_name = 'VIC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "349d5a80-eb75-4f6b-a28e-5120215ada8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 pred loss: 151.2948, reg_loss: 210.8976, val loss: nan\n",
      "Epoch 1 total loss: 145.2396, pred loss: 144.4348, reg_loss: 80.4860, val loss: nan\n",
      "Epoch 6 total loss: 69.4841, pred loss: 69.0368, reg_loss: 44.7317, val loss: nan\n",
      "Epoch 11 total loss: 43.8797, pred loss: 43.6616, reg_loss: 21.8073, val loss: nan\n",
      "Epoch 16 total loss: 33.9699, pred loss: 33.7160, reg_loss: 25.3886, val loss: nan\n",
      "Epoch 21 total loss: 29.3166, pred loss: 29.0769, reg_loss: 23.9760, val loss: nan\n",
      "Epoch 26 total loss: 26.9986, pred loss: 26.7692, reg_loss: 22.9425, val loss: nan\n",
      "Epoch 31 total loss: 26.6741, pred loss: 26.4396, reg_loss: 23.4555, val loss: nan\n"
     ]
    }
   ],
   "source": [
    "# soil class scalar using log, random start, scaled\n",
    "_error_fn = _rmse\n",
    "error_fn_name = 'rmse'\n",
    "\n",
    "train_loss_out, pred_loss_out, reg_loss_out, val_loss_out, theta = train_and_store(subset_name = subset_name,\n",
    "                                                                                   obs_name = obs_name,\n",
    "                                                                                   _error_fn = _error_fn,\n",
    "                                                                                   error_fn_name = error_fn_name,\n",
    "                                                                                   learning_rate = 0.001,\n",
    "                                                                                   n_epochs = 30,\n",
    "                                                                                   val_frac = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ab6a6-8fb7-4278-89b5-36201d682b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb46dd6-c971-4c2a-a6fe-7b41afec608f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb1b7ab2-0ffd-4dfb-8e0e-315c78e7be37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 pred loss: 193.0402, reg_loss: 275.4830, val loss: nan\n",
      "Epoch 1 total loss: 188.6235, pred loss: 187.8289, reg_loss: 79.4585, val loss: nan\n",
      "Epoch 6 total loss: 126.1107, pred loss: 125.7390, reg_loss: 37.1648, val loss: nan\n",
      "Epoch 11 total loss: 72.8450, pred loss: 72.5604, reg_loss: 28.4649, val loss: nan\n",
      "Epoch 16 total loss: 46.6197, pred loss: 46.3994, reg_loss: 22.0373, val loss: nan\n",
      "Epoch 21 total loss: 37.7458, pred loss: 37.4790, reg_loss: 26.6730, val loss: nan\n",
      "Epoch 26 total loss: 33.6993, pred loss: 33.4204, reg_loss: 27.8836, val loss: nan\n",
      "Epoch 31 total loss: 32.5981, pred loss: 32.3313, reg_loss: 26.6761, val loss: nan\n"
     ]
    }
   ],
   "source": [
    "# soil class scalar using log, random start\n",
    "_error_fn = _rmse\n",
    "error_fn_name = 'rmse'\n",
    "\n",
    "train_loss_out, pred_loss_out, reg_loss_out, val_loss_out, theta = train_and_store(subset_name = subset_name,\n",
    "                                                                                   obs_name = obs_name,\n",
    "                                                                                   _error_fn = _error_fn,\n",
    "                                                                                   error_fn_name = error_fn_name,\n",
    "                                                                                   learning_rate = 0.001,\n",
    "                                                                                   n_epochs = 30,\n",
    "                                                                                   val_frac = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14e21297-78f4-4e48-9d83-e56fdcd9ead9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 pred loss: 135.3471, reg_loss: 619.0754, val loss: nan\n",
      "Epoch 1 total loss: 117.6131, pred loss: 116.4815, reg_loss: 113.1661, val loss: nan\n",
      "Epoch 6 total loss: 51.9875, pred loss: 51.4211, reg_loss: 56.6422, val loss: nan\n",
      "Epoch 11 total loss: 42.1469, pred loss: 41.7205, reg_loss: 42.6382, val loss: nan\n",
      "Epoch 16 total loss: 38.3026, pred loss: 37.9357, reg_loss: 36.6916, val loss: nan\n",
      "Epoch 21 total loss: 36.0634, pred loss: 35.7291, reg_loss: 33.4250, val loss: nan\n",
      "Epoch 26 total loss: 34.8380, pred loss: 34.5312, reg_loss: 30.6831, val loss: nan\n",
      "Epoch 31 total loss: 34.2670, pred loss: 33.9823, reg_loss: 28.4617, val loss: nan\n"
     ]
    }
   ],
   "source": [
    "# NOAH + regression on soil contents using log, random start\n",
    "_error_fn = _rmse\n",
    "error_fn_name = 'rmse'\n",
    "\n",
    "train_loss_out, pred_loss_out, reg_loss_out, val_loss_out, theta = train_and_store(subset_name = subset_name,\n",
    "                                                                                   obs_name = obs_name,\n",
    "                                                                                   _error_fn = _error_fn,\n",
    "                                                                                   error_fn_name = error_fn_name,\n",
    "                                                                                   learning_rate = 0.001,\n",
    "                                                                                   n_epochs = 30,\n",
    "                                                                                   val_frac = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f507a9f5-188a-4a31-8124-3009179601fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 pred loss: 123.8417, reg_loss: 195.7297, val loss: nan\n",
      "Epoch 1 total loss: 112.4669, pred loss: 111.8620, reg_loss: 60.4960, val loss: nan\n",
      "Epoch 6 total loss: 64.0041, pred loss: 63.6166, reg_loss: 38.7476, val loss: nan\n",
      "Epoch 11 total loss: 48.7567, pred loss: 48.4685, reg_loss: 28.8285, val loss: nan\n",
      "Epoch 16 total loss: 44.0785, pred loss: 43.8326, reg_loss: 24.5905, val loss: nan\n",
      "Epoch 21 total loss: 41.5831, pred loss: 41.3319, reg_loss: 25.1146, val loss: nan\n",
      "Epoch 26 total loss: 39.6683, pred loss: 39.4182, reg_loss: 25.0046, val loss: nan\n",
      "Epoch 31 total loss: 38.1857, pred loss: 37.9466, reg_loss: 23.9035, val loss: nan\n"
     ]
    }
   ],
   "source": [
    "# NOAH, log, random start\n",
    "_error_fn = _rmse\n",
    "error_fn_name = 'rmse'\n",
    "\n",
    "train_loss_out, pred_loss_out, reg_loss_out, val_loss_out, theta = train_and_store(subset_name = subset_name,\n",
    "                                                                                   obs_name = obs_name,\n",
    "                                                                                   _error_fn = _error_fn,\n",
    "                                                                                   error_fn_name = error_fn_name,\n",
    "                                                                                   learning_rate = 0.001,\n",
    "                                                                                   n_epochs = 30,\n",
    "                                                                                   val_frac = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "620a8ab1-74c4-4f45-8eb2-8b9c3f8cbb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 pred loss: 139.6269, reg_loss: 0.0000, val loss: nan\n",
      "Epoch 1 total loss: 115.5750, pred loss: 115.4117, reg_loss: 16.3227, val loss: nan\n",
      "Epoch 6 total loss: 39.4394, pred loss: 39.2534, reg_loss: 18.6035, val loss: nan\n",
      "Epoch 11 total loss: 36.1339, pred loss: 35.9304, reg_loss: 20.3449, val loss: nan\n",
      "Epoch 16 total loss: 34.4622, pred loss: 34.2524, reg_loss: 20.9795, val loss: nan\n",
      "Epoch 21 total loss: 33.8736, pred loss: 33.6661, reg_loss: 20.7497, val loss: nan\n",
      "Epoch 26 total loss: 33.6492, pred loss: 33.4455, reg_loss: 20.3705, val loss: nan\n",
      "Epoch 31 total loss: 33.4985, pred loss: 33.2909, reg_loss: 20.7576, val loss: nan\n"
     ]
    }
   ],
   "source": [
    "# NOAH + regression on soil contents using log\n",
    "_error_fn = _rmse\n",
    "error_fn_name = 'rmse'\n",
    "\n",
    "train_loss_out, pred_loss_out, reg_loss_out, val_loss_out, theta = train_and_store(subset_name = subset_name,\n",
    "                                                                                   obs_name = obs_name,\n",
    "                                                                                   _error_fn = _error_fn,\n",
    "                                                                                   error_fn_name = error_fn_name,\n",
    "                                                                                   learning_rate = 0.001,\n",
    "                                                                                   n_epochs = 30,\n",
    "                                                                                   val_frac = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85ba39f1-4283-4075-b3ed-00a3e13ec6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 pred loss: 398.7293, reg_loss: 149.0950, val loss: nan\n",
      "Epoch 1 total loss: 357.0240, pred loss: 356.3212, reg_loss: 70.2793, val loss: nan\n",
      "Epoch 6 total loss: 109.7697, pred loss: 109.0889, reg_loss: 68.0762, val loss: nan\n",
      "Epoch 11 total loss: 55.9770, pred loss: 55.7513, reg_loss: 22.5671, val loss: nan\n",
      "Epoch 16 total loss: 46.4427, pred loss: 46.3075, reg_loss: 13.5284, val loss: nan\n",
      "Epoch 21 total loss: 41.7153, pred loss: 41.5609, reg_loss: 15.4350, val loss: nan\n",
      "Epoch 26 total loss: 39.8752, pred loss: 39.7038, reg_loss: 17.1428, val loss: nan\n",
      "Epoch 31 total loss: 39.2561, pred loss: 39.0825, reg_loss: 17.3580, val loss: nan\n"
     ]
    }
   ],
   "source": [
    "# Regression on soil contents plus intercept using log, random start\n",
    "_error_fn = _rmse\n",
    "error_fn_name = 'rmse'\n",
    "\n",
    "train_loss_out, pred_loss_out, reg_loss_out, val_loss_out, theta = train_and_store(subset_name = subset_name,\n",
    "                                                                                   obs_name = obs_name,\n",
    "                                                                                   _error_fn = _error_fn,\n",
    "                                                                                   error_fn_name = error_fn_name,\n",
    "                                                                                   learning_rate = 0.001,\n",
    "                                                                                   n_epochs = 30,\n",
    "                                                                                   val_frac = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77d9231b-6c57-48b9-8f63-13dc7f8faf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 pred loss: 56.6325, reg_loss: 0.0000, val loss: nan\n",
      "Epoch 1 total loss: 49.9408, pred loss: 49.8898, reg_loss: 5.1048, val loss: nan\n",
      "Epoch 6 total loss: 40.4870, pred loss: 40.3236, reg_loss: 16.3395, val loss: nan\n",
      "Epoch 11 total loss: 39.0435, pred loss: 38.8532, reg_loss: 19.0305, val loss: nan\n",
      "Epoch 16 total loss: 38.5324, pred loss: 38.3486, reg_loss: 18.3766, val loss: nan\n",
      "Epoch 21 total loss: 38.1424, pred loss: 37.9535, reg_loss: 18.8949, val loss: nan\n",
      "Epoch 26 total loss: 37.8405, pred loss: 37.6562, reg_loss: 18.4250, val loss: nan\n",
      "Epoch 31 total loss: 37.6220, pred loss: 37.4392, reg_loss: 18.2792, val loss: nan\n"
     ]
    }
   ],
   "source": [
    "# Regression on soil contents plus intercept using log\n",
    "_error_fn = _rmse\n",
    "error_fn_name = 'rmse'\n",
    "\n",
    "train_loss_out, pred_loss_out, reg_loss_out, val_loss_out, theta = train_and_store(subset_name = subset_name,\n",
    "                                                                                   obs_name = obs_name,\n",
    "                                                                                   _error_fn = _error_fn,\n",
    "                                                                                   error_fn_name = error_fn_name,\n",
    "                                                                                   learning_rate = 0.001,\n",
    "                                                                                   n_epochs = 30,\n",
    "                                                                                   val_frac = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8c994d7-6090-459a-8da4-0e7d800be859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 pred loss: 56.2360, reg_loss: 0.0000, val loss: nan\n",
      "Epoch 1 total loss: 49.7308, pred loss: 49.6789, reg_loss: 5.1875, val loss: nan\n",
      "Epoch 6 total loss: 40.0404, pred loss: 39.8642, reg_loss: 17.6196, val loss: nan\n",
      "Epoch 11 total loss: 39.1196, pred loss: 38.9322, reg_loss: 18.7309, val loss: nan\n",
      "Epoch 16 total loss: 38.4627, pred loss: 38.2776, reg_loss: 18.5110, val loss: nan\n",
      "Epoch 21 total loss: 37.9999, pred loss: 37.8117, reg_loss: 18.8236, val loss: nan\n",
      "Epoch 26 total loss: 37.7233, pred loss: 37.5467, reg_loss: 17.6600, val loss: nan\n",
      "Epoch 31 total loss: 37.5629, pred loss: 37.3785, reg_loss: 18.4447, val loss: nan\n"
     ]
    }
   ],
   "source": [
    "# Regression on soil contents using log\n",
    "_error_fn = _rmse\n",
    "error_fn_name = 'rmse'\n",
    "\n",
    "train_loss_out, pred_loss_out, reg_loss_out, val_loss_out, theta = train_and_store(subset_name = subset_name,\n",
    "                                                                                   obs_name = obs_name,\n",
    "                                                                                   _error_fn = _error_fn,\n",
    "                                                                                   error_fn_name = error_fn_name,\n",
    "                                                                                   learning_rate = 0.001,\n",
    "                                                                                   n_epochs = 30,\n",
    "                                                                                   val_frac = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b74bf2b8-75a0-4512-bae7-9bbd3ca72e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 pred loss: 56.2178, reg_loss: 0.0000, val loss: nan\n",
      "Epoch 1 total loss: 54.7293, pred loss: 54.6346, reg_loss: 9.4750, val loss: nan\n",
      "Epoch 6 total loss: 46.0005, pred loss: 45.8825, reg_loss: 11.7977, val loss: nan\n",
      "Epoch 11 total loss: 45.2821, pred loss: 45.1470, reg_loss: 13.5068, val loss: nan\n",
      "Epoch 16 total loss: 44.7553, pred loss: 44.6166, reg_loss: 13.8699, val loss: nan\n",
      "Epoch 21 total loss: 44.3233, pred loss: 44.1600, reg_loss: 16.3280, val loss: nan\n",
      "Epoch 26 total loss: 43.9569, pred loss: 43.7966, reg_loss: 16.0265, val loss: nan\n",
      "Epoch 31 total loss: 43.6540, pred loss: 43.4892, reg_loss: 16.4812, val loss: nan\n"
     ]
    }
   ],
   "source": [
    "# Regression on soil contents using non-log\n",
    "_error_fn = _rmse\n",
    "error_fn_name = 'rmse'\n",
    "\n",
    "train_loss_out, pred_loss_out, reg_loss_out, val_loss_out, theta = train_and_store(subset_name = subset_name,\n",
    "                                                                                   obs_name = obs_name,\n",
    "                                                                                   _error_fn = _error_fn,\n",
    "                                                                                   error_fn_name = error_fn_name,\n",
    "                                                                                   learning_rate = 0.001,\n",
    "                                                                                   n_epochs = 30,\n",
    "                                                                                   val_frac = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e9230a-d22a-4317-ae66-ef84df102e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c10b78-78ac-4912-b5f7-daba0f967211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Parallelize with dask delayed\n",
    "# delayed = []\n",
    "\n",
    "# for _error_fn, error_fn_name in zip(_error_fns, error_fn_names):\n",
    "#     # Hyperparameter adjustments\n",
    "#     if error_fn_name == 'kge':\n",
    "#         reg_const = 0.001\n",
    "#     else:\n",
    "#         reg_const = 0.01\n",
    "\n",
    "#     if error_fn_name == 'mse':\n",
    "#         learning_rate = 1e-3\n",
    "#     else:\n",
    "#         learning_rate = 1e-2\n",
    "        \n",
    "#     for batch_size in [2**5, 2**6, 2**7, 2**8, 2**9]:\n",
    "#         delayed.append(dask.delayed(train_and_store)(subset_name = subset_name,\n",
    "#                                                      obs_name = obs_name,\n",
    "#                                                      _error_fn = _error_fn,\n",
    "#                                                      error_fn_name = error_fn_name,\n",
    "#                                                      batch_size = batch_size,\n",
    "#                                                      reg_const = reg_const,\n",
    "#                                                      learning_rate = learning_rate,\n",
    "#                                                      n_epochs = 30,\n",
    "#                                                      val_frac = 0.0))\n",
    "\n",
    "# out = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5f30aa-6bdc-491c-9efb-4adcf412fcde",
   "metadata": {},
   "source": [
    "### MOSAIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34239120-98d7-44a9-be56-2061e53f8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info\n",
    "subset_name = 'centralUS'\n",
    "obs_name = 'MOSAIC'\n",
    "\n",
    "# needed for quantile RMSE\n",
    "N = np.load(f'{project_data_path}/WBM/calibration/{subset_name}/{obs_name}/{obs_name}_validation.npy').shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f882d851-9169-4706-b866-fb52b3c33c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 23s, sys: 20.8 s, total: 4min 43s\n",
      "Wall time: 56min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "\n",
    "for _error_fn, error_fn_name in zip(_error_fns, error_fn_names):\n",
    "    # Hyperparameter adjustments\n",
    "    if error_fn_name == 'kge':\n",
    "        reg_const = 0.001\n",
    "    else:\n",
    "        reg_const = 0.01\n",
    "\n",
    "    if error_fn_name == 'mse':\n",
    "        learning_rate = 1e-3\n",
    "    else:\n",
    "        learning_rate = 1e-2\n",
    "        \n",
    "    for batch_size in [2**5, 2**6, 2**7, 2**8, 2**9]:\n",
    "        delayed.append(dask.delayed(train_and_store)(subset_name = subset_name,\n",
    "                                                     obs_name = obs_name,\n",
    "                                                     _error_fn = _error_fn,\n",
    "                                                     error_fn_name = error_fn_name,\n",
    "                                                     batch_size = batch_size,\n",
    "                                                     reg_const = reg_const,\n",
    "                                                     learning_rate = learning_rate,\n",
    "                                                     n_epochs = 30,\n",
    "                                                     val_frac = 0.0))\n",
    "\n",
    "out = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dac970-d6d5-454a-a595-7c7d44487e61",
   "metadata": {},
   "source": [
    "### NOAH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a960759-af42-4edb-8066-ad431f90c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info\n",
    "subset_name = 'centralUS'\n",
    "obs_name = 'NOAH'\n",
    "\n",
    "# needed for quantile RMSE\n",
    "N = np.load(f'{project_data_path}/WBM/calibration/{subset_name}/{obs_name}/{obs_name}_validation.npy').shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e9352-6283-411a-97ec-ce4866781bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Parallelize with dask delayed\n",
    "delayed = []\n",
    "\n",
    "for _error_fn, error_fn_name in zip(_error_fns, error_fn_names):\n",
    "    # Hyperparameter adjustments\n",
    "    if error_fn_name == 'kge':\n",
    "        reg_const = 0.001\n",
    "    else:\n",
    "        reg_const = 0.01\n",
    "\n",
    "    if error_fn_name == 'mse':\n",
    "        learning_rate = 1e-3\n",
    "    else:\n",
    "        learning_rate = 1e-2\n",
    "        \n",
    "    for batch_size in [2**5, 2**6, 2**7, 2**8, 2**9]:\n",
    "        delayed.append(dask.delayed(train_and_store)(subset_name = subset_name,\n",
    "                                                     obs_name = obs_name,\n",
    "                                                     _error_fn = _error_fn,\n",
    "                                                     error_fn_name = error_fn_name,\n",
    "                                                     batch_size = batch_size,\n",
    "                                                     reg_const = reg_const,\n",
    "                                                     learning_rate = learning_rate,\n",
    "                                                     n_epochs = 30,\n",
    "                                                     val_frac = 0.0))\n",
    "\n",
    "out = dask.compute(*delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872df4b-4415-4b2d-a666-2b98dd230e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137beaed-9ad8-4da4-bade-d02819c31ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
